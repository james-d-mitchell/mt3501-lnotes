<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
   "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="en" xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" href="data:;base64,iVBORw0KGgo=" />
    <link rel="stylesheet" href="../css/math.css" />
    
    
    <title>MT3501 Lecture Notes | </title>
    <style type="text/css">
  body {
    font-size: 150%;
    font-family: muli,avenir,helvetica neue,helvetica,ubuntu,roboto,noto,segoe ui,arial,sans-serif;
  }
</style>

</head>
<body><p><a name="nav-menu" id="nav-menu"><strong>Contents</strong></a></p>

<ul>
    
    <li>
      <a href="/mt3501-lnotes/">
      
      Home
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/01-intro/">
      
      Section 1 - Intro
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/02-vector-spaces/">
      
      Section 2 - Vector spaces
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/03-algorithms-to-live-by/">
      
      Section 3 - Algorithms to live by
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/04-linear-transf/">
      
      Section 4 - Linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/05-l-v-w/">
      
      Section 5 - The vector space of linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/06-direct-sums/">
      
      Section 6 - Direct sums
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/07-dual-space/">
      
      Section 7 - The dual space
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/08-eigen-stuff/">
      
      Section 8 - Eigenvectors, eigenvalues, and the characteristic polynomial
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/09-diagonal/">
      
      Section 9 - Diagonalisation
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/10-jnf/">
      
      Section 10 - Jordan normal form
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/11-inner-products/">
      
      Section 11 - Inner products
      </a>
    </li>
    
</ul>



    <script
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"
        type="text/javascript"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    





  </p>






<h1 id="direct-sums">Direct sums</h1>
<style type="text/css" scoped>
  body {
    counter-reset: chapter 5;
  }
</style>

<h2 id="definition-and-basic-properties">Definition and basic properties</h2>
<div class="defn">
<p><span id="de-direct-sum" label="de-direct-sum"></span> Let <span class="math inline">\(V\)</span> be a vector space and <span class="math inline">\(U_{1}\)</span> and <span class="math inline">\(U_{2}\)</span> be subspaces of <span class="math inline">\(V\)</span>. We say that <span class="math inline">\(V\)</span> is the <strong><em>direct sum</em></strong> of <span class="math inline">\(U_{1}\)</span> and <span class="math inline">\(U_{2}\)</span>, written <span class="math inline">\(V = U_{1} \oplus U_{2}\)</span> if the following conditions hold:</p>
<ol type="1">
<li><p><span class="math inline">\(V = U_{1} + U_{2}\)</span>,</p></li>
<li><p><span class="math inline">\(U_{1} \cap U_{2} = \{\vec{0}\}\)</span>.</p></li>
</ol>
</div>
<div class="prop">
<p><span id="prop-direct-sum-unique" label="prop-direct-sum-unique"></span> Let <span class="math inline">\(V\)</span> be a vector space over a field <span class="math inline">\(F\)</span> and let <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span> be subspaces of <span class="math inline">\(V\)</span>. Then <span class="math inline">\(V = U_1 \oplus U_2\)</span> if and only if every vector <span class="math inline">\(v\in V\)</span> can be expressed <em>uniquely</em> in the form <span class="math inline">\(u_{1} + u_{2}\)</span> where <span class="math inline">\(u_{1} \in U_{1}\)</span> and <span class="math inline">\(u_{2} \in U_{2}\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> (<span class="math inline">\(\Rightarrow\)</span>) Suppose that <span class="math inline">\(v = u_1 + u_2 = u_1&#39; + u_2&#39;\)</span> where <span class="math inline">\(u_1, u_1&#39;\in U_1\)</span> and <span class="math inline">\(u_2,  u_2&#39;\in U_2\)</span>. Then <span class="math inline">\(U_1 \ni u_1 - u_1&#39; = u_2&#39; - u_2 \in U_2\)</span> and so <span class="math inline">\(u_1 -  u_1&#39; = u_2&#39; - u_2\in U_1 \cap U_2 = \{\vec{0}\}\)</span>. It follows that <span class="math inline">\(u_1 =  u_1&#39;\)</span> and <span class="math inline">\(u_2 = u_2&#39;\)</span>. Therefore <span class="math inline">\(v = u_1 + u_2\)</span> is the unique sum of a vector in <span class="math inline">\(U_1\)</span> and a vector in <span class="math inline">\(U_2\)</span> equal to <span class="math inline">\(v\)</span>.</p>
<p>(<span class="math inline">\(\Leftarrow\)</span>) Clearly <a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#de-direct-sum">Definition 6.1.1</a>(1) holds. Suppose that <span class="math inline">\(u\in U_1\cap  U_2\subseteq V\)</span>. Then there exist unique <span class="math inline">\(u_1\in U_1\)</span> and <span class="math inline">\(u_2\in U_2\)</span> such that <span class="math inline">\(u = u_1 + u_2\)</span>. But <span class="math inline">\(\vec{0}\in U_1\)</span>, <span class="math inline">\(u\in U_2\)</span>, and <span class="math inline">\(u = \vec{0} + u\)</span>, and so, by uniqueness, <span class="math inline">\(u_1 = \vec{0}\)</span>. Similarly, <span class="math inline">\(u\in U_1\)</span>, <span class="math inline">\(\vec{0}\in U_2\)</span>, and <span class="math inline">\(u = u + \vec{0}\)</span>, and so, by uniqueness <span class="math inline">\(u_2 = \vec{0}\)</span>. Therefore <span class="math inline">\(u = u_1 + u_2 = \vec{0} + \vec{0} =  \vec{0}\)</span> and so <span class="math inline">\(U_1\cap U_2 = \{\vec{0}\}\)</span>. ◻</p>
</div>
<div class="prop">
<p><span id="prop-dirsum-basis" label="prop-dirsum-basis"></span> Let <span class="math inline">\(V\)</span> be a finite-dimensional vector space, let <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span> be subspaces of <span class="math inline">\(V\)</span>, and let <span class="math inline">\(\mathscr{B}_1\)</span> and <span class="math inline">\(\mathscr{B}_2\)</span> be any spanning sets for <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span>, respectively. Then <span class="math inline">\(V = U_1 \oplus U_2\)</span>, and <span class="math inline">\(\mathscr{B}_1\)</span> and <span class="math inline">\(\mathscr{B}_2\)</span> are bases for <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span>, respectively, if and only if <span class="math inline">\(\mathscr{B}_{1} \cup \mathscr{B}_{2}\)</span> is a basis for <span class="math inline">\(V\)</span> and <span class="math inline">\(\mathscr{B}_1\cap \mathscr{B}_2 = \varnothing\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Let <span class="math inline">\(\mathscr{B}_{1} = \{ u_{1},u_{2},\dots,u_{m} \}\)</span> and <span class="math inline">\(\mathscr{B}_{2} = \{  v_{1},v_{2},\dots,v_{n} \}\)</span>.</p>
<p>(<span class="math inline">\(\Rightarrow\)</span>) Since <span class="math inline">\(V = U_1\oplus U_2\)</span>, it follows from the definition that <span class="math inline">\(U_1\cap U_2=  \{\vec{0}\}\)</span>. But <span class="math inline">\(\vec{0}\)</span> is not contained in any basis for any vector space and so <span class="math inline">\(\mathscr{B}_1\cap \mathscr{B}_2 = \varnothing\)</span>.</p>
<p>If <span class="math inline">\(v \in V\)</span>, then <span class="math inline">\(v = x + y\)</span> where <span class="math inline">\(x \in U_{1}\)</span> and <span class="math inline">\(y \in U_{2}\)</span>. Since <span class="math inline">\(\mathscr{B}_{1}\)</span> and <span class="math inline">\(\mathscr{B}_{2}\)</span> span <span class="math inline">\(U_{1}\)</span> and <span class="math inline">\(U_{2}\)</span>, respectively, there exist scalars <span class="math inline">\(\alpha_{i}\)</span> and <span class="math inline">\(\beta_{j}\)</span> such that <span class="math display">\[x = \alpha_{1}u_{1} + \dots + \alpha_{m}u_{m} \qquad \text{and}
    \qquad y = \beta_{1}v_{1} + \dots + \beta_{n}v_{n}.\]</span> Then <span class="math display">\[v = x+y = \alpha_{1}u_{1} + \dots + \alpha_{m}u_{m} +
    \beta_{1}v_{1} + \dots + \beta_{n}v_{n}\]</span> and it follows that <span class="math inline">\(\mathscr{B} = \{  u_{1},u_{2},\dots,u_{m},v_{1},v_{2},\dots,v_{n} \}\)</span> spans <span class="math inline">\(V\)</span>.</p>
<p>It remains to prove that <span class="math inline">\(\mathscr{B}\)</span> is linearly independent. Suppose that <span class="math display">\[\gamma_{1} u_{1} + \dots + \gamma_{m} u_{m} + \delta_{1} v_{1} +
    \dots + \delta_{n} v_{n} = \vec{0}\]</span> for some scalars <span class="math inline">\(\gamma_{i}\)</span>, <span class="math inline">\(\delta_{i}\)</span>. Put <span class="math display">\[x = \gamma_{1} u_{1} + \dots + \gamma_{m} u_{m} \in U_{1} \qquad
    \text{and} \qquad y = \delta_{1} v_{1} + \dots + \delta_{n} v_{n} \in U_{2}.\]</span> Then <span class="math inline">\(x + y = \vec{0}\)</span> must be the unique decomposition of <span class="math inline">\(\vec{0}\)</span> produced by the direct sum <span class="math inline">\(V = U_{1} \oplus U_{2}\)</span>. But <span class="math inline">\(\vec{0} + \vec{0} = \vec{0}\)</span>, and so <span class="math inline">\(x = \vec{0}\)</span> and <span class="math inline">\(y = \vec{0}\)</span> (by uniqueness), and hence <span class="math display">\[\gamma_{1} u_{1} + \dots + \gamma_{m} u_{m} = x = \vec{0} \qquad
    \text{and} \qquad \delta_{1} v_{1} + \dots + \delta_{n} v_{n} = y = \vec{0}.\]</span> Linear independence of <span class="math inline">\(\mathscr{B}_{1}\)</span> and <span class="math inline">\(\mathscr{B}_{2}\)</span> implies that <span class="math display">\[\gamma_{1} = \dots = \gamma_{m} = 0 \qquad \text{and} \qquad
    \delta_{1} = \dots = \delta_{n} = 0.\]</span> Hence <span class="math inline">\(\mathscr{B} = \mathscr{B}_{1} \cup \mathscr{B}_{2}\)</span> is linearly independent and therefore a basis for <span class="math inline">\(V\)</span>.</p>
<p>(<span class="math inline">\(\Leftarrow\)</span>) If <span class="math inline">\(\mathscr{B}_1 \cup \mathscr{B}_2\)</span> is linearly independent, then so too are <span class="math inline">\(\mathscr{B}_1\)</span> and <span class="math inline">\(\mathscr{B}_2\)</span>, and so <span class="math inline">\(\mathscr{B}_1\)</span> and <span class="math inline">\(\mathscr{B}_2\)</span> are bases for <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span>.</p>
<p>To show that <span class="math inline">\(V = U_1\oplus U_2\)</span>, it suffices, by <a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#prop-dirsum-basis">Proposition 6.1.3</a>, to show that every <span class="math inline">\(v\in V\)</span> can be given uniquely in the form <span class="math inline">\(x + y\)</span> where <span class="math inline">\(x\in U_1\)</span> and <span class="math inline">\(y\in U_2\)</span>.</p>
<p>Let <span class="math inline">\(v\in V\)</span> be arbitrary. Since <span class="math inline">\(\mathscr{B}_1\cup \mathscr{B}_2\)</span> is a basis for <span class="math inline">\(V\)</span>, there exist unique <span class="math inline">\(\alpha_1, \alpha_2, \ldots, \alpha_m, \beta_1, \beta_2, \ldots, \beta_n\in  F\)</span> such that <span class="math display">\[v = \alpha_{1} u_{1} + \dots + \alpha_{m} u_{m} + \beta_{1} v_{1} +
    \dots + \beta_{n} v_{n}.\]</span> If <span class="math inline">\(x = \alpha_{1} u_{1} + \dots + \alpha_{m} u_{m}\in \operatorname{Span}(\mathscr{B}_1) = U_1\)</span> and <span class="math inline">\(y = \beta_{1} v_{1} + \dots + \beta_{n} v_{n} \in \operatorname{Span}(\mathscr{B}_2) = U_2\)</span>, then certainly <span class="math inline">\(v = x + y\)</span>. The linear combination of vectors in <span class="math inline">\(\mathscr{B}_1\cup \mathscr{B}_2\)</span> that equals <span class="math inline">\(v\)</span> is unique, and so, since <span class="math inline">\(\mathscr{B}_1\cap \mathscr{B}_2=  \varnothing\)</span>, it follows that <span class="math inline">\(x\in U_1\)</span> and <span class="math inline">\(y\in U_2\)</span> are unique also. ◻</p>
</div>
<div class="cor">
<p>If <span class="math inline">\(V = U_{1} \oplus U_{2}\)</span> is a finite-dimensional vector space expressed as a direct sum of two subspaces, then <span class="math display">\[\dim V = \dim U_{1} + \dim U_{2}.\]</span> 0◻</p>
</div>
<div class="exampjupyter">
<p><span id="ex:dirsum1" label="ex:dirsum1"></span> Let <span class="math inline">\(V = \mathbb{R}^{3}\)</span> and let <span class="math display">\[U_{1} = \operatorname{Span} \left( \vec{v}_1 = \begin{pmatrix} 1 \\ 1 \\ 1 \\ \end{pmatrix},
    \vec{v}_2 = \begin{pmatrix} 2 \\ 1 \\ 0 \\ \end{pmatrix} \right) \qquad \text{and} \qquad U_{2} =
    \operatorname{Span} \left( \vec{v}_3 = \begin{pmatrix} 0 \\ 3 \\ 1 \\ \end{pmatrix} \right).\]</span> Show that <span class="math inline">\(V = U_{1} \oplus U_{2}\)</span>.</p>
</div>
<div class="solution">
<p>Since <span class="math inline">\(\{\vec{v}_1, \vec{v}_2\} \cap \{\vec{v}_3\} = \varnothing\)</span> it suffices, by <a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#prop-dirsum-basis">Proposition 6.1.3</a>, to show that <span class="math inline">\(\{\vec{v}_1, \vec{v}_2, \vec{v}_3\}\)</span> is a basis for <span class="math inline">\(V\)</span>.</p>
<p>Let us solve <span class="math display">\[\alpha \begin{pmatrix} 1 \\ 1 \\ 1 \\ \end{pmatrix} + \beta \begin{pmatrix} 2 \\ 1 \\ 0 \\ \end{pmatrix} + \gamma
    \begin{pmatrix} 0 \\ 3 \\ 1 \\ \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ \end{pmatrix}.\]</span> We find <span class="math display">\[\alpha + 2\beta = \alpha + \beta + 3\gamma = \alpha + \gamma = 0.\]</span> Thus <span class="math inline">\(\gamma = -\alpha\)</span>, so the second equation gives <span class="math inline">\(\beta -  2\alpha = 0\)</span>;  i.e., <span class="math inline">\(\beta = 2\alpha\)</span>. Hence <span class="math inline">\(5\alpha = 0\)</span>, so <span class="math inline">\(\alpha = 0\)</span> which implies <span class="math inline">\(\beta = \gamma = 0\)</span>. Thus the three vectors <span class="math display">\[\begin{pmatrix} 1 \\ 1 \\ 1 \\ \end{pmatrix}, \begin{pmatrix} 2 \\ 1 \\ 0 \\ \end{pmatrix}, \begin{pmatrix} 0 \\ 3 \\ 1 \\ \end{pmatrix}\]</span> are linearly independent and hence form a basis for <span class="math inline">\(\mathbb{R}^{3}\)</span>.</p>
</div>
<p><a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#ex:dirsum1">Example 6.1.5</a> is in some sense typical of direct sums. To gain a visual understanding, the following picture illustrates the <span class="math inline">\(3\)</span>-dimensional space <span class="math inline">\(\mathbb{R}^{3}\)</span> as the direct sum of a <span class="math inline">\(1\)</span>-dimensional subspace <span class="math inline">\(U_{1}\)</span> and a <span class="math inline">\(2\)</span>-dimensional subspace <span class="math inline">\(U_{2}\)</span> (these being a line and a plane passing through the origin, respectively).</p>
<figure>
<img src="static/picture" alt="image" /><figcaption aria-hidden="true">image</figcaption>
</figure>
<h2 id="section-projection-maps">Projection maps</h2>
<div class="defn">
<p>Let <span class="math inline">\(V = U_{1} \oplus U_{2}\)</span> be a vector space expressed as a direct sum of two subspaces. Then the <strong><em>projection maps</em></strong> <span class="math inline">\(P_{1} :  V \to U_1\)</span> and <span class="math inline">\(P_{2} : V \to U_2\)</span> of the direct sum <span class="math inline">\(U_{1} \oplus U_{2}\)</span> are defined by <span class="math display">\[P_{1}(v) = u_{1} \qquad \text{and} \qquad P_{2}(v) = u_{2}.\]</span> where <span class="math inline">\(v\in V\)</span>, <span class="math inline">\(u_1\in U_1\)</span>, <span class="math inline">\(u_2\in U_2\)</span> and <span class="math inline">\(v = u_1 + u_2\)</span> is the unique expression of <span class="math inline">\(v\)</span>.</p>
</div>
<div class="lemma">
<p><span id="lem:proj" label="lem:proj"></span> Let <span class="math inline">\(V = U_{1} \oplus U_{2}\)</span> be a direct sum of subspaces with projection map <span class="math inline">\(P_{i} : V \to U_i\)</span> where <span class="math inline">\(i = 1\)</span> or <span class="math inline">\(2\)</span>. Then:</p>
<ol type="1">
<li><p><span class="math inline">\(P_{i}\)</span> is a linear transformation;</p></li>
<li><p><span class="math inline">\(P_{1}(u) = u\)</span> for all <span class="math inline">\(u \in U_{1}\)</span> and <span class="math inline">\(P_{1}(w) = \vec{0}\)</span> for all <span class="math inline">\(w \in U_{2}\)</span>;</p></li>
<li><p><span class="math inline">\(\ker P_1 = U_2\)</span>, <span class="math inline">\(\operatorname{im} P_1 = U_1\)</span>, <span class="math inline">\(\ker P_2 = U_1\)</span>, and <span class="math inline">\(\operatorname{im} P_2 = U_2\)</span>.</p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em> <strong>(1).</strong> Let <span class="math inline">\(v,v&#39; \in V\)</span> and write <span class="math inline">\(v = u_{1}+u_{2}\)</span>,  <span class="math inline">\(v&#39; =  u&#39;_{1}+u&#39;_{2}\)</span> where <span class="math inline">\(u_{1},u&#39;_{1} \in U_{1}\)</span> and <span class="math inline">\(u_{2},u&#39;_{2} \in  U_{2}\)</span>. Then <span class="math display">\[v + v&#39; = (u_{1}+u&#39;_{1}) + (u_{2}+u&#39;_{2})\]</span> and <span class="math inline">\(u_{1}+u&#39;_{1} \in U_{1}\)</span>,  <span class="math inline">\(u_{2}+u&#39;_{2} \in U_{2}\)</span>. This must be the unique decomposition for <span class="math inline">\(v+v&#39;\)</span>, so <span class="math display">\[P_1(v+v&#39;) = u_{1}+u&#39;_{1} = P_1(v) + P_1(v&#39;).\]</span> Similarly, if <span class="math inline">\(\alpha \in F\)</span>, then <span class="math inline">\(\alpha v = \alpha u_{1} + \alpha  u_{2}\)</span> and <span class="math inline">\(\alpha u_{1} \in U_{1}\)</span> and <span class="math inline">\(\alpha u_{2} \in U_{2}\)</span>. Thus <span class="math display">\[P_1(\alpha v) = \alpha u_{1} = \alpha P_1(v).\]</span> Hence <span class="math inline">\(P\)</span> is a linear transformation.</p>
<p><strong>(2).</strong> If <span class="math inline">\(u \in U_{1}\)</span>, then <span class="math inline">\(u = u+\vec{0}\)</span> and so <span class="math inline">\(P_1(u) = u\)</span>. If <span class="math inline">\(w \in U_{2}\)</span>, then <span class="math inline">\(w = \vec{0}+w\)</span> and so <span class="math inline">\(P_1(w) = \vec{0}\)</span>.</p>
<p><strong>(3).</strong> By part (2), <span class="math inline">\(U_2\)</span> is contained in <span class="math inline">\(\ker P_1\)</span>. On the other hand, if <span class="math inline">\(v\in  \ker P_1\)</span>, then <span class="math inline">\(P_1(v) = \vec{0}\)</span> and so <span class="math inline">\(v = \vec{0} + u_2\)</span>, for some <span class="math inline">\(u_2\in U_2\)</span> must be the unique sum of a vector in <span class="math inline">\(U_1\)</span> and a vector in <span class="math inline">\(U_2\)</span> equal to <span class="math inline">\(v\)</span>. Hence <span class="math inline">\(v = u_2\in U_2\)</span>, and so <span class="math inline">\(\ker P_1 = U_2\)</span>.</p>
<p>Clearly <span class="math inline">\(\operatorname{im} P_1 \subseteq U_1\)</span> by the definition of <span class="math inline">\(P_1\)</span>. On the other hand, if <span class="math inline">\(u\in U_1\)</span> is arbitrary, then <span class="math inline">\(u = P_1(u)\)</span> (by part (2) again), and so <span class="math inline">\(\operatorname{im} P_1 = U_1\)</span>. ◻</p>
</div>
<p>The major facts about projections are the following:</p>
<div class="prop">
<p><span id="prop:proj" label="prop:proj"></span> Let <span class="math inline">\(P : V \to V\)</span> be a projection corresponding to some direct sum decomposition of the vector space <span class="math inline">\(V\)</span>. Then</p>
<ol type="1">
<li><p><span class="math inline">\(P^{2} = P\)</span>;</p></li>
<li><p><span class="math inline">\(V = \ker P \oplus \operatorname{im} P\)</span>;</p></li>
<li><p><span class="math inline">\(\operatorname{id}-P\)</span> is also a projection;</p></li>
<li><p><span class="math inline">\(V = \ker P \oplus \ker(\operatorname{id}-P)\)</span>;</p></li>
</ol>
<p>where <span class="math inline">\(\operatorname{id} : V \to V\)</span> denotes the identity transformation defined by <span class="math inline">\(\operatorname{id}(v) = v\)</span> for all <span class="math inline">\(v\in V\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Suppose that <span class="math inline">\(V = U_1 \oplus U_2\)</span>, and that <span class="math inline">\(P = P_1\)</span>.</p>
<p><strong>(1).</strong> If <span class="math inline">\(v \in V\)</span>, then <span class="math inline">\(P_1(v) \in U_{1}\)</span>, so by <a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#lem:proj">Lemma 6.2.2</a>(2), <span class="math display">\[P_1^{2}(v) = P_1(P_1(v)) = P_1(v)\]</span> and so <span class="math inline">\(P_1^{2} = P_1\)</span>.</p>
<p><strong>(2).</strong> Again, by <a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#lem:proj">Lemma 6.2.2</a>(3), <span class="math inline">\(\ker P_1 = U_{2}\)</span> and <span class="math inline">\(\operatorname{im} P_1 = U_{1}\)</span>, so <span class="math display">\[V = U_{1} \oplus U_{2} = \operatorname{im} P_1 \oplus \ker P_1.\]</span></p>
<p><strong>(3).</strong> Let <span class="math inline">\(P_2 : V \to U_2\)</span> be the projection onto <span class="math inline">\(U_{2}\)</span>. If <span class="math inline">\(v \in V\)</span>, say <span class="math inline">\(v = u_{1}+u_{2}\)</span> where <span class="math inline">\(u_{1} \in  U_{1}\)</span> and <span class="math inline">\(u_{2} \in U_{2}\)</span>, then <span class="math display">\[P_2(v) = u_{2} = v-u_{1} = v - P_1(v) = (\operatorname{id}-P_1)(v).\]</span> Hence <span class="math inline">\(\operatorname{id} - P_1\)</span> is the projection <span class="math inline">\(P_2\)</span>.</p>
<p><strong>(4).</strong> Again by <a href="https://jdbm.me/mt3501-lnotes/06-direct-sums/#lem:proj">Lemma 6.2.2</a>(3), <span class="math inline">\(\ker P_1 = U_{2}\)</span> and, since <span class="math inline">\(\operatorname{id} - P_1 = P_2\)</span>, <span class="math inline">\(\ker \operatorname{id} - P_1 = \ker P_2 =  U_{1}\)</span>. Hence <span class="math display">\[V = U_{1} \oplus U_{2} = \ker(\operatorname{id}-P_1) \oplus \ker P_1.\]</span> ◻</p>
</div>
<p>We give an example to illustrate how projection maps depend on both summands in the direct sum decomposition.</p>
<div class="exampjupyter">
<p>Let <span class="math display">\[U_{1} = \operatorname{Span}\begin{pmatrix} 1 \\ 0 \end{pmatrix}, \quad 
    U_{2} = \operatorname{Span}\begin{pmatrix} 0 \\ 1 \end{pmatrix}, \quad \text{and} \quad
    U_{3} = \operatorname{Span}\begin{pmatrix} 1 \\ 1 \end{pmatrix}.\]</span></p>
<ol type="1">
<li><p>Show that <span class="math display">\[\mathbb{R}^{2} = U_{1} \oplus U_{2} \qquad \text{and} \qquad \mathbb{R}^{2} = U_{1}
    \oplus U_{3}.\]</span></p></li>
<li><p>If <span class="math inline">\(P : \mathbb{R}^{2} \to \mathbb{R}^{2}\)</span> is the projection onto <span class="math inline">\(U_{1}\)</span> corresponding to the first decomposition and <span class="math inline">\(Q : \mathbb{R}^{2} \to  \mathbb{R}^{2}\)</span> is the projection onto <span class="math inline">\(U_{1}\)</span> corresponding to the second decomposition, that <span class="math inline">\(P \neq Q\)</span>.</p></li>
</ol>
</div>
<div class="solution">
<p><strong>(1).</strong> If <span class="math inline">\(\vec{v} = \begin{pmatrix} x \\ y \end{pmatrix} \in \mathbb{R}^{2}\)</span>, then <span class="math display">\[\vec{v} = \begin{pmatrix} x \\ y \end{pmatrix} = x\begin{pmatrix} 1 \\ 0 \end{pmatrix} + y \begin{pmatrix} 0 \\ 1 \end{pmatrix}\]</span> and <span class="math display">\[\vec{v} = \begin{pmatrix} x \\ y \end{pmatrix} = (x-y)\begin{pmatrix} 1 \\ 0 \end{pmatrix} + y\begin{pmatrix} 1 \\ 1 \end{pmatrix}.\]</span> Hence <span class="math inline">\(\mathbb{R}^{2} = U_{1} + U_{2} = U_{1} + U_{3}\)</span>. Moreover, <span class="math display">\[U_{1} = \left\{ \begin{pmatrix} x \\ 0 \end{pmatrix} \;\middle|\; x \in \mathbb{R} \right\} \qquad
    \text{and} \qquad U_{2} = \left\{ \begin{pmatrix} 0 \\ y \end{pmatrix} \;\middle|\; y \in \mathbb{R} \right\},\]</span> so <span class="math inline">\(U_{1} \cap U_{2} = \{\vec{0}\}\)</span>. Therefore we do have a direct sum <span class="math inline">\(\mathbb{R}^{2} = U_{1} \oplus U_{2}\)</span>. Similarly, one can see <span class="math inline">\(U_{1} \cap  U_{3} = \{\vec{0}\}\)</span>, so the second sum is also direct.</p>
<p><strong>(2).</strong> It suffices to find a <span class="math inline">\(\vec{v} \in \mathbb{R} ^ 2\)</span> such that <span class="math inline">\(P(\vec{v}) \neq Q(\vec{v})\)</span>.</p>
<p>If <span class="math inline">\(\vec{v}\in U_1\)</span> that</p>
<p><span class="math display">\[P(\vec{v}) = Q(\vec{v}) = \vec{v}\]</span> and so we will have to take <span class="math inline">\(\vec{v}\in \mathbb{R} ^ 2 \setminus U_1\)</span>.</p>
<p>If <span class="math inline">\(\vec{v} = \begin{pmatrix} 3 \\ 2 \end{pmatrix} \in \mathbb{R}^{2}\)</span>, then <span class="math inline">\(\vec{v}\not\in U_1\)</span> and we obtain different values for <span class="math inline">\(P(\vec{v})\)</span> and <span class="math inline">\(Q(\vec{v})\)</span>. Indeed <span class="math display">\[\begin{pmatrix} 3 \\ 2 \end{pmatrix} = \begin{pmatrix} 3 \\ 0 \end{pmatrix} + \begin{pmatrix} 0 \\ 2 \end{pmatrix}\]</span> is the decomposition corresponding to <span class="math inline">\(\mathbb{R}^{2} = U_{1} \oplus U_{2}\)</span> which yields <span class="math display">\[P\begin{pmatrix} 3 \\ 2 \end{pmatrix} = \begin{pmatrix} 3 \\ 0 \end{pmatrix} \in U_{1}\]</span> while <span class="math display">\[\begin{pmatrix} 3 \\ 2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} + \begin{pmatrix} 2 \\ 2 \end{pmatrix}\]</span> is that corresponding to <span class="math inline">\(\mathbb{R}^{2} = U_{1} \oplus U_{3}\)</span> which yields <span class="math display">\[Q\begin{pmatrix} 3 \\ 2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \in U_{1}.\]</span> Alternatively, <span class="math inline">\(\ker P = U_{2} \neq \ker Q = U_{3}\)</span>, which is more information indicating the difference between these two transformations.</p>
</div>
<div class="omittedexampjupyter">
<p>Let <span class="math inline">\(V = \mathbb{R}^{3}\)</span> and <span class="math inline">\(U = \operatorname{Span}(\vec{v}_{1})\)</span>, where <span class="math display">\[\vec{v}_{1} = 
    \begin{pmatrix}
      3 \\
      -1 \\
      2 \\
    \end{pmatrix}.\]</span></p>
<ol type="1">
<li><p>Find a subspace <span class="math inline">\(W\)</span> such that <span class="math inline">\(V = U \oplus W\)</span>.</p></li>
<li><p>Let <span class="math inline">\(P : V \to V\)</span> be the associated projection onto <span class="math inline">\(W\)</span>. Calculate <span class="math inline">\(P(\vec{u})\)</span> where <span class="math display">\[\vec{u} = 
        \begin{pmatrix}
          4 \\
          4 \\
          4 \\
        \end{pmatrix}.\]</span></p></li>
</ol>
</div>
<div class="solution">
<p>(1) We first extend <span class="math inline">\(\{\vec{v}_{1}\}\)</span> to a basis for <span class="math inline">\(\mathbb{R}^{3}\)</span>. We claim that <span class="math display">\[\mathscr{B} = \left\{ \begin{pmatrix} 3 \\ -1 \\ 2 \\ \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ 0 \\ \end{pmatrix},
    \begin{pmatrix} 0 \\ 1 \\ 0 \\ \end{pmatrix} \right\}\]</span> is a basis for <span class="math inline">\(\mathbb{R}^{3}\)</span>. We solve <span class="math display">\[\alpha \begin{pmatrix} 3 \\ -1 \\ 2 \\ \end{pmatrix} + \beta \begin{pmatrix} 1 \\ 0 \\ 0 \\ \end{pmatrix} + \gamma
    \begin{pmatrix} 0 \\ 1 \\ 0 \\ \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ \end{pmatrix};\]</span> that is, <span class="math display">\[3\alpha + \beta = -\alpha + \gamma = 2\alpha = 0.\]</span> Hence <span class="math inline">\(\alpha = 0\)</span>, so <span class="math inline">\(\beta = -3\alpha = 0\)</span> and <span class="math inline">\(\gamma = \alpha =  0\)</span>. Thus <span class="math inline">\(\mathscr{B}\)</span> is linearly independent. Since <span class="math inline">\(\dim V = 3\)</span> and <span class="math inline">\(|\mathscr{B}| = 3\)</span>, we conclude that <span class="math inline">\(\mathscr{B}\)</span> is a basis for <span class="math inline">\(\mathbb{R}^{3}\)</span>.</p>
<p>Let <span class="math inline">\(W = \operatorname{Span}(\vec{v}_{2},\vec{v}_{3})\)</span> where <span class="math display">\[\vec{v}_{2} = \begin{pmatrix} 1 \\ 0 \\ 0 \\ \end{pmatrix} \qquad \text{and} \qquad
    \vec{v}_{3} = \begin{pmatrix} 0 \\ 1 \\ 0 \\ \end{pmatrix}.\]</span> Since <span class="math inline">\(\mathscr{B} = \{ \vec{v}_{1}, \vec{v}_{2}, \vec{v}_{3} \}\)</span> is a basis for <span class="math inline">\(V\)</span>, if <span class="math inline">\(\vec{v} \in V\)</span>, then there exist <span class="math inline">\(\alpha_{1},\alpha_{2},\alpha_{3} \in \mathbb{R}\)</span> such that <span class="math display">\[\vec{v} = (\alpha_{1}\vec{v}_{1}) + (\alpha_{2}\vec{v}_{2} +
    \alpha_{3}\vec{v}_{3}) \in U + W.\]</span> Hence <span class="math inline">\(V = U+W\)</span>.</p>
<p>If <span class="math inline">\(\vec{v} \in U \cap W\)</span>, then there exist <span class="math inline">\(\alpha,\beta_{1},\beta_{2} \in \mathbb{R}\)</span> such that <span class="math display">\[\vec{v} = \alpha \vec{v}_{1} = \beta_{1}\vec{v}_{2} + \beta_{2}\vec{v}_{3}.\]</span> Therefore <span class="math display">\[\alpha\vec{v}_{1} + (-\beta_{1})\vec{v}_{2} +
    (-\beta_{2})\vec{v}_{3} = \vec{0}.\]</span> Since <span class="math inline">\(\mathscr{B}\)</span> is linearly independent, we conclude <span class="math inline">\(\alpha = -\beta_{1}  = -\beta_{2} = 0\)</span>, so <span class="math inline">\(\vec{v} = \alpha \vec{v}_{1} = \vec{0}\)</span>. Thus <span class="math inline">\(U \cap W = \{\vec{0}\}\)</span> and so <span class="math display">\[V = U \oplus W.\]</span></p>
<p>(2) We write <span class="math inline">\(\vec{u}\)</span> as a linear combination of the basis <span class="math inline">\(\mathscr{B}\)</span>. Inspection shows <span class="math display">\[\begin{aligned}
    \vec{u} = \begin{pmatrix} 4 \\ 4 \\ 4 \\ \end{pmatrix} &amp; = 2 \begin{pmatrix} 3 \\ -1 \\ 2 \\ \end{pmatrix} - 2
    \begin{pmatrix} 1 \\ 0 \\ 0 \\ \end{pmatrix} + 6 \begin{pmatrix} 0 \\ 1 \\ 0 \\ \end{pmatrix}                                     \\
                                   &amp; = \begin{pmatrix} 6 \\ -2 \\ 4 \\ \end{pmatrix} + \begin{pmatrix} -2 \\ 6 \\ 0 \\ \end{pmatrix},
  \end{aligned}\]</span> where the first term in the last line belongs to <span class="math inline">\(U\)</span> and the second to <span class="math inline">\(W\)</span>. Hence <span class="math display">\[P(\vec{u}) = \begin{pmatrix} -2 \\ 6 \\ 0 \\ \end{pmatrix}\]</span> (since this is the <span class="math inline">\(W\)</span> component of <span class="math inline">\(\vec{u}\)</span>).</p>
</div>
<h2 id="direct-sums-of-more-summands">Direct sums of more summands</h2>
<p>We briefly address the situation when <span class="math inline">\(V\)</span> is expressed as a direct sum of more than two subspaces.</p>
<div class="defn">
<p>Let <span class="math inline">\(V\)</span> be a vector space. We say that <span class="math inline">\(V\)</span> is the <strong><em>direct sum</em></strong> of subspaces <span class="math inline">\(U_{1}\)</span>, <span class="math inline">\(U_{2}\)</span>, …, <span class="math inline">\(U_{k}\)</span>, written <span class="math inline">\(V = U_{1}  \oplus U_{2} \oplus \dots \oplus U_{k}\)</span>, if the following conditions hold:</p>
<ol type="1">
<li><p><span class="math inline">\(V = U_{1} + U_{2} + \dots + U_{k}\)</span>;</p></li>
<li><p><span class="math inline">\(U_{i} \cap (U_{1} + \dots + U_{i-1} + U_{i+1} + \dots +  U_{k}) = \{\vec{0}\}\)</span> for each <span class="math inline">\(i\)</span>.</p></li>
</ol>
</div>
<p>Again this can be translated into a condition stating that every vector can be given uniquely as a sum of vectors in each of the subspaces comprising the direct sum. We omit the proof.</p>
<div class="prop">
<p>Let <span class="math inline">\(V\)</span> be a vector space with subspaces <span class="math inline">\(U_{1}\)</span>, <span class="math inline">\(U_{2}\)</span>, …, <span class="math inline">\(U_{k}\)</span>. Then <span class="math inline">\(V = U_{1} \oplus U_{2} \oplus \dots \oplus U_{k}\)</span> if and only if every vector in <span class="math inline">\(V\)</span> can be <em>uniquely</em> expressed in the form <span class="math inline">\(u_{1} + u_{2} +  \dots + u_{k}\)</span> where <span class="math inline">\(u_{i} \in U_{i}\)</span> for each <span class="math inline">\(i\)</span>.</p>
</div>







<p><a href="#">Back to top</a></p>
<ul>
    
    <li>
      <a href="/mt3501-lnotes/">
      
      Home
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/01-intro/">
      
      Section 1 - Intro
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/02-vector-spaces/">
      
      Section 2 - Vector spaces
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/03-algorithms-to-live-by/">
      
      Section 3 - Algorithms to live by
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/04-linear-transf/">
      
      Section 4 - Linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/05-l-v-w/">
      
      Section 5 - The vector space of linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/06-direct-sums/">
      
      Section 6 - Direct sums
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/07-dual-space/">
      
      Section 7 - The dual space
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/08-eigen-stuff/">
      
      Section 8 - Eigenvectors, eigenvalues, and the characteristic polynomial
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/09-diagonal/">
      
      Section 9 - Diagonalisation
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/10-jnf/">
      
      Section 10 - Jordan normal form
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/11-inner-products/">
      
      Section 11 - Inner products
      </a>
    </li>
    
</ul>
<footer>
<hr>⚡️
	2021  © J. D. Mitchell  
</footer>
</body>
</html>
