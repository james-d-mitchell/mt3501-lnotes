<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
   "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="en" xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" href="data:;base64,iVBORw0KGgo=" />
    <link rel="stylesheet" href="../css/math.css" />
    
    
    <title>MT3501 Lecture Notes | </title>
    <style type="text/css">
  body {
    font-size: 150%;
    font-family: muli,avenir,helvetica neue,helvetica,ubuntu,roboto,noto,segoe ui,arial,sans-serif;
  }
</style>

</head>
<body><p><a name="nav-menu" id="nav-menu"><strong>Contents</strong></a></p>

<ul>
    
    <li>
      <a href="/mt3501-lnotes/">
      
      Home
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/01-intro/">
      
      Section 1 - Intro
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/02-vector-spaces/">
      
      Section 2 - Vector spaces
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/03-algorithms-to-live-by/">
      
      Section 3 - Algorithms to live by
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/04-linear-transf/">
      
      Section 4 - Linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/05-l-v-w/">
      
      Section 5 - The vector space of linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/06-direct-sums/">
      
      Section 6 - Direct sums
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/07-dual-space/">
      
      Section 7 - The dual space
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/08-eigen-stuff/">
      
      Section 8 - Eigenvectors, eigenvalues, and the characteristic polynomial
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/09-diagonal/">
      
      Section 9 - Diagonalisation
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/10-jnf/">
      
      Section 10 - Jordan normal form
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/11-inner-products/">
      
      Section 11 - Inner products
      </a>
    </li>
    
</ul>



    <script
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"
        type="text/javascript"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    





  </p>






<h1 id="chapter-algorithms">Algorithms to live by</h1>
<style type="text/css" scoped>
  body {
    counter-reset: chapter 2;
  }
</style>

<h2 id="preamble">Preamble</h2>
<p>You learned one algorithm in MT2501, and this is really the only algorithm required for the linear algebra computations in this course too. The algorithm is <strong><em>Gaussian elimination</em></strong>. The following are the different types of problems you can solve using Gaussian elimination:</p>
<ol type="1">
<li><p>Show that a collection <span class="math inline">\(\mathscr{A}\)</span> of vectors in a vector space <span class="math inline">\(V\)</span> is linearly independent or linearly dependent;</p></li>
<li><p>Find the dimension of a subspace <span class="math inline">\(W\)</span> spanned by some collection <span class="math inline">\(\mathscr{A}\)</span> of vectors;</p></li>
<li><p>Find a basis for a subspace <span class="math inline">\(W\)</span> spanned by some collection <span class="math inline">\(\mathscr{A}\)</span> of vectors;</p></li>
<li><p>Find a linear combination of vectors equal to some vector.</p></li>
</ol>
<p>In this section, we will show why and how you can use Gaussian elimination to solve these types of problems by hand.</p>
<p>Almost no one performs linear algebra calculations by hand today, this is error prone, and precisely the type of thing that computers are much better at than human beings. Given that you spent an entire semester in MT2501 perfecting the obsolete art of performing Gaussian elimination by hand, we are not going to do any Gaussian elimination in MT3501, but I am instead going to use a computer. While I encourage you to use a computer also, and there are some computing resources available for this module, you are welcome to do it the old fashioned way, if you want to. You are also free to use any computing resources that you choose, you do not have to use those provided as part of this module. However, when it comes to Gaussian elimination and resolving the related problems in this module, I will only be able to provide support for the computing resources provided as part of this module, and not other resources (including your hand computations).</p>
<p>Why include a section about how to perform these algorithms by hand, when we will use computers instead? The purpose is two-fold: firstly, for completeness, to show you what is possible, and why it is valid; secondly, to demonstrate that using a computer is superior.</p>
<p>When covering this material in lectures, I will concentrate on:</p>
<ul>
<li><p>how to theoretically apply Gaussian elimination to resolve problems of the above types;</p></li>
<li><p>how to practically perform such computations with the aid of a computer.</p></li>
</ul>
<p>I will not go through the proofs of why the various algorithms are valid, nor how to perform Gaussian elimination by hand; both of these aspects are covered in full detail in the notes below.</p>
<h2 id="gaussian-elimination">Gaussian elimination</h2>
<p>We recall a bunch of stuff from MT2501 that is useful in this section and course. [The material in this section is a summary of the section of a similar name in the MT2501 notes.]</p>
<p>Recall from MT2501, that a matrix is in <em>row-echelon form</em> if it looks like: <span class="math display">\[\begin{pmatrix}
    \ast   &amp; \ast   &amp; \ast   &amp; \cdots &amp; \cdots &amp; \ast     \\
    0      &amp; \ast   &amp; \ast   &amp; \cdots &amp; \cdots &amp; \ast     \\
    0      &amp; 0      &amp; \ast   &amp; \cdots &amp; \cdots &amp; \ast     \\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp;        &amp; \vdots   \\
    0      &amp; 0      &amp; 0      &amp; \cdots &amp; \ast   &amp; \ast   &amp;
  \end{pmatrix}
  \qquad\text{for example}\qquad
  \begin{pmatrix}
    1 &amp; 2 &amp; 3 &amp; 4  &amp; 5  \\
    0 &amp; 6 &amp; 7 &amp; 8  &amp; 9  \\
    0 &amp; 0 &amp; 0 &amp; 10 &amp; 11 \\
    0 &amp; 0 &amp; 0 &amp; 0  &amp; 12
  \end{pmatrix}\]</span> while a matrix is in <strong><em>reduced row-echelon form</em></strong> if it looks like: <span class="math display">\[% The following is not completely ideal, but it&#39;s the same as used in MT2501
  % in 2018-19 so probably good enough.
  \begin{pmatrix}
    1      &amp; 0      &amp; \ldots &amp; 0      \\
    0      &amp; 1      &amp; \ldots &amp; 0      \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    0      &amp; 0      &amp; \ldots &amp; 1      \\
    0      &amp; 0      &amp; \ldots &amp; 0      \\
    0      &amp; 0      &amp; \ldots &amp; 0      \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    0      &amp; 0      &amp; \ldots &amp; 0      \\
  \end{pmatrix}
  \qquad\text{for example}\qquad
  \begin{pmatrix}
    1 &amp; 0 &amp; 2 &amp; 0 &amp; 3 \\
    0 &amp; 1 &amp; 4 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1 &amp; 5 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
  \end{pmatrix}\]</span></p>
<p>If <span class="math inline">\(r_i\)</span> denotes the <span class="math inline">\(i\)</span>th row of a matrix <span class="math inline">\(A\)</span>, then <strong><em>elementary row operations</em></strong> on <span class="math inline">\(A\)</span> are:</p>
<ul>
<li><p>interchanging of two rows (<span class="math inline">\(r_i \leftrightarrow r_j\)</span>, <span class="math inline">\(i\neq j\)</span>);</p></li>
<li><p>multiplying a row by a non-zero scalar <span class="math inline">\(\lambda\)</span> (<span class="math inline">\(r_i \rightarrow \lambda  r_i\)</span>, <span class="math inline">\(\lambda \neq 0\)</span>);</p></li>
<li><p>adding a non-zero scalar multiple of another row to a row (<span class="math inline">\(r_i \rightarrow  r_i + \lambda r_j\)</span>, <span class="math inline">\(i \neq j\)</span>).</p></li>
</ul>
<div class="defn">
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <span class="math inline">\(m \times n\)</span> matrices with entries from a field <span class="math inline">\(F\)</span>, then we say that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong><em>row-equivalent</em></strong> if <span class="math inline">\(B\)</span> can be obtained from <span class="math inline">\(A\)</span> by a finite sequence of elementary row operations.</p>
</div>
<div class="prop">
<p><span id="HUGO_REPLACE_prop-row-echelon_Proposition-3.2.2" label="HUGO_REPLACE_prop-row-echelon_Proposition-3.2.2"></span> If <span class="math inline">\(A\)</span> is a non-zero matrix, then:</p>
<ol type="1">
<li><p><span class="math inline">\(A\)</span> is row-equivalent to a row-echelon matrix;</p></li>
<li><p><span class="math inline">\(A\)</span> is row-equivalent to a unique reduced row-echelon matrix.</p></li>
</ol>
</div>
<p>There can be many echelon matrices that are row-equivalent to a given matrix, but only one reduced row-echelon matrix.</p>
<p><strong><em>Elementary column operations</em></strong>, <strong><em>column-equivalent</em></strong>, <strong><em>column-echelon</em></strong>, and <strong><em>reduced column-echelon</em></strong> are defined analogously to their “row” counterparts, and the analogue of <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_prop-row-echelon_Proposition-3.2.2">Proposition 3.2.2</a> holds too.</p>
<div class="defn">
<p>If <span class="math inline">\(A\)</span> is an <span class="math inline">\(m \times n\)</span> matrix with entries from a field <span class="math inline">\(F\)</span>, then the set <span class="math inline">\(\mathcal{R}\)</span> of rows of <span class="math inline">\(A\)</span> can be viewed as row vectors in <span class="math inline">\(F ^ n\)</span>. The subspace of <span class="math inline">\(F ^ n\)</span> spanned by <span class="math inline">\(\mathcal{R}\)</span> is called the <strong><em>row-space</em></strong> of <span class="math inline">\(A\)</span>; and is denoted by <span class="math inline">\(\operatorname{Row}(A)\)</span>.</p>
<p>If <span class="math inline">\(\mathcal{C}\)</span> is the set of columns of <span class="math inline">\(A\)</span>, then the <strong><em>column-space</em></strong> of <span class="math inline">\(A\)</span> is just <span class="math inline">\(\operatorname{Span}(\mathcal{C})\)</span> in <span class="math inline">\(F ^ m\)</span> and is denoted <span class="math inline">\(\operatorname{Col}(A)\)</span>.</p>
</div>
<div class="prop">
<p><span id="HUGO_REPLACE_prop-row-equiv_Proposition-3.2.4" label="HUGO_REPLACE_prop-row-equiv_Proposition-3.2.4"></span> Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be <span class="math inline">\(m \times n\)</span> matrices with entries from a field <span class="math inline">\(F\)</span>. Then the following hold:</p>
<ol type="1">
<li><p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are row-equivalent if and only if <span class="math inline">\(\operatorname{Row}(A) = \operatorname{Row}(B)\)</span>;</p></li>
<li><p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are column-equivalent if and only if <span class="math inline">\(\operatorname{Col}(A) = \operatorname{Col}(B)\)</span>.</p></li>
</ol>
</div>
<p>Another way of stating <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_prop-row-equiv_Proposition-3.2.4">Proposition 3.2.4</a>(1) is to say that the row-space of a matrix is <em>invariant</em> (i.e. does not change) under elementary row operations. Similarly, the column-space of a matrix is invariant under elementary column operations.</p>
<div class="examp">
<p><span id="HUGO_REPLACE_examp-row-ops-do-not-preserve-col-space_Example-3.2.5" label="HUGO_REPLACE_examp-row-ops-do-not-preserve-col-space_Example-3.2.5"></span> Show that the column space of the matrix <span class="math display">\[A =
    \begin{pmatrix}
      1 &amp; 0 \\
      1 &amp; 0
    \end{pmatrix}\]</span> does not equal the column space in <span class="math inline">\(\mathbb{R} ^ 2\)</span> of the reduced row-echelon matrix <span class="math inline">\(E\)</span> that’s row-equivalent to <span class="math inline">\(A\)</span>.</p>
</div>
<div class="solution">
<p>Certainly, <span class="math display">\[\begin{pmatrix} 1 \\ 1 \end{pmatrix} \in \operatorname{Col}(A).\]</span> But <span class="math display">\[E =
    \begin{pmatrix}
      1 &amp; 0 \\
      0 &amp; 0
    \end{pmatrix}\]</span> and so <span class="math display">\[\operatorname{Col}(E) = \left\{ \begin{pmatrix} x \\ 0 \end{pmatrix} : x\in \mathbb{R}\right\}.\]</span> Clearly, <span class="math display">\[\begin{pmatrix} 1 \\ 1 \end{pmatrix}\not\in \operatorname{Col}(E)\]</span> and so <span class="math inline">\(\operatorname{Col}(E) \not=\operatorname{Col}(A)\)</span>.</p>
</div>
<div class="prop">
<p><span id="HUGO_REPLACE_prop-row-echelon-basis_Proposition-3.2.6" label="HUGO_REPLACE_prop-row-echelon-basis_Proposition-3.2.6"></span> The non-zero rows in a row echelon form matrix <span class="math inline">\(E\)</span> form a basis for the row-space <span class="math inline">\(\operatorname{Row}(E)\)</span>.</p>
<p>The non-zero columns in a column echelon form matrix <span class="math inline">\(E\)</span> form a basis for the column-space <span class="math inline">\(\operatorname{Col}(E)\)</span>.</p>
</div>
<p>We end this section by stating a theorem that you might not have see before, but which in any case you might have used. We saw in <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_examp-row-ops-do-not-preserve-col-space_Example-3.2.5">Example 3.2.5</a> that row-operations do not preserve the column-space of a matrix, but they do preserve its null-space.</p>
<div class="thm">
<p><span id="HUGO_REPLACE_thm-row-ops-preserve-null-space_Theorem-3.2.7" label="HUGO_REPLACE_thm-row-ops-preserve-null-space_Theorem-3.2.7"></span> Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be row-equivalent <span class="math inline">\(m \times n\)</span> matrices with entries in a field <span class="math inline">\(F\)</span>, and let <span class="math inline">\(\vec{v}\in F ^ n\)</span>. Then <span class="math inline">\(A\vec{v} = \vec{0}\)</span> if and only if <span class="math inline">\(B\vec{v} = \vec{0}\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Suppose that <span class="math display">\[A =
    \begin{pmatrix}
      \alpha_{11}   &amp; \alpha_{12}   &amp; \cdots &amp; \alpha_{1n} \\
      \alpha_{21}   &amp; \alpha_{22}   &amp; \cdots &amp; \alpha_{2n} \\
      \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots \\
      \alpha_{m{1}} &amp; \alpha_{m{2}} &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}.\]</span> and suppose that <span class="math display">\[\vec{v} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}\in F ^ n\]</span> is such that <span class="math inline">\(A\vec{v} = \vec{0}\)</span>. It follows that <span class="math display">\[\label{eq-prod}
    \alpha_{j1}v_1 + \alpha_{j2}v_2 + \cdots + \alpha_{jn}v_n = \sum_{i = 1}^ {n} \alpha_{ji}v_i = 0\]</span> for all <span class="math inline">\(j\)</span>.</p>
<p>It suffices to show that if <span class="math inline">\(B\)</span> is an <span class="math inline">\(m\times n\)</span> matrix obtained from <span class="math inline">\(A\)</span> by a single elementary row operation, then <span class="math inline">\(Bv = \vec{0}\)</span> also. There are three elementary row operations which we consider in separate cases.</p>
<p><strong>Case 1:</strong> <em>Interchanging two rows.</em> Suppose that <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by interchanging the first and second row. Then <span class="math display">\[B =
    \begin{pmatrix}
      \alpha_{21}   &amp; \alpha_{22}   &amp; \cdots &amp; \alpha_{2n} \\
      \alpha_{11}   &amp; \alpha_{12}   &amp; \cdots &amp; \alpha_{1n} \\
      \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots \\
      \alpha_{m{1}} &amp; \alpha_{m{2}} &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}.\]</span> Then <span class="math display">\[B\vec{v} =
    \begin{pmatrix}
      \alpha_{21}   &amp; \alpha_{22}   &amp; \cdots &amp; \alpha_{2n} \\
      \alpha_{11}   &amp; \alpha_{12}   &amp; \cdots &amp; \alpha_{1n} \\
      \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots \\
      \alpha_{m{1}} &amp; \alpha_{m{2}} &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}
    \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}
    =
    \begin{pmatrix}
      \alpha_{21}v_1 + \alpha_{22}v_2 + \cdots + \alpha_{2n}v_n \\
      \alpha_{11}v_1 + \alpha_{12}v_2 + \cdots + \alpha_{1n}v_n \\
      \vdots\\
      \alpha_{m1}v_1 + \alpha_{m2}v_2 + \cdots + \alpha_{mn}v_n
    \end{pmatrix}.\]</span> But from above <span class="math display">\[\alpha_{j1}v_1 + \alpha_{j2}v_2 + \cdots + \alpha_{jn}v_n = 0\]</span> for every <span class="math inline">\(j\)</span>, and so <span class="math inline">\(B\vec{v} = \vec{0}\)</span> also.</p>
<p><strong>Case 2:</strong> <em>Multiplying a row by a non-zero scalar.</em> Suppose that <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by multiplying the first row by the scalar <span class="math inline">\(\alpha\in F\)</span>. Then <span class="math display">\[B =
    \begin{pmatrix}
      \alpha \alpha_{11} &amp; \alpha  \alpha_{12} &amp; \cdots &amp; \alpha \alpha_{1n} \\
      \alpha_{21}        &amp; \alpha_{22}         &amp; \cdots &amp; \alpha_{2n}        \\
      \vdots        &amp; \vdots         &amp; \ddots &amp; \vdots        \\
      \alpha_{m{1}}      &amp; \alpha_{m{2}}       &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}.\]</span> Then <span class="math display">\[\begin{aligned}
    B\vec{v} &amp; = &amp;
    \begin{pmatrix}
      \alpha \alpha_{11} &amp; \alpha  \alpha_{12} &amp; \cdots &amp; \alpha \alpha_{1n} \\
      \alpha_{21}        &amp; \alpha_{22}         &amp; \cdots &amp; \alpha_{2n}        \\
      \vdots        &amp; \vdots         &amp; \ddots &amp; \vdots        \\
      \alpha_{m{1}}      &amp; \alpha_{m{2}}       &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}
    \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}
    \\
    &amp; = &amp;
    \begin{pmatrix}
      \alpha \alpha_{11}v_1 + \alpha \alpha_{12}v_2 + \cdots + \alpha \alpha_{1n}v_n 
      \\
      \alpha_{21}v_1 + \alpha_{22}v_2 + \cdots + \alpha_{2n}v_n \\
      \vdots \\
      \alpha_{m1}v_1 + \alpha_{m2}v_2 + \cdots + \alpha_{mn}v_n 
    \end{pmatrix} \\
    &amp; = &amp;
    \begin{pmatrix}
    \alpha (\alpha_{11}v_1 + \alpha_{12}v_2 + \cdots + \alpha_{1n}v_n) \\
    \alpha_{21}v_1 + \alpha_{22}v_2 + \cdots + \alpha_{2n}v_n \\
    \vdots \\
    \alpha_{m1}v_1 + \alpha_{m2}v_2 + \cdots + \alpha_{mn}v_n
    \end{pmatrix} \\
    &amp; = &amp; \vec{0},
  \end{aligned}\]</span> from above and since <span class="math inline">\(\alpha 0 = 0\)</span>.</p>
<p><strong>Case 3:</strong> <em>Adding a non-zero scalar multiple of another row to a row.</em> Suppose that <span class="math inline">\(B\)</span> is obtained from <span class="math inline">\(A\)</span> by adding the second row multiplied by <span class="math inline">\(\alpha\in F\)</span> to the first row. Then <span class="math display">\[B =
    \begin{pmatrix}
      \alpha_{11} + \alpha \alpha_{12} &amp; \alpha_{12} + \alpha \alpha_{22} &amp; \cdots &amp; \alpha_{1n} +
      \alpha \alpha_{2n}                                                       \\
      \alpha_{21}                 &amp; \alpha_{22}                 &amp; \cdots &amp; \alpha_{2n}   \\
      \alpha_{21}                 &amp; \alpha_{22}                 &amp; \cdots &amp; \alpha_{2n}   \\
      \vdots                 &amp; \vdots                 &amp; \ddots &amp; \vdots   \\
      \alpha_{m{1}}               &amp; \alpha_{m{2}}               &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}.\]</span> Hence <span class="math display">\[\begin{aligned}
    B\vec{v} &amp; = &amp;
    \begin{pmatrix}
      \alpha_{11} + \alpha \alpha_{12} &amp; \alpha_{12} + \alpha \alpha_{22} &amp; \cdots &amp; \alpha_{1n} +
      \alpha \alpha_{2n}                                                       \\
      \alpha_{21}                 &amp; \alpha_{22}                 &amp; \cdots &amp; \alpha_{2n}   \\
      \alpha_{21}                 &amp; \alpha_{22}                 &amp; \cdots &amp; \alpha_{2n}   \\
      \vdots                 &amp; \vdots                 &amp; \ddots &amp; \vdots   \\
      \alpha_{m{1}}               &amp; \alpha_{m{2}}               &amp; \cdots &amp; \alpha_{mn}
    \end{pmatrix}
    \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} \\
    &amp; = &amp;
    \begin{pmatrix}
      (\alpha_{11} + \alpha \alpha_{12})v_1 + (\alpha_{12} + \alpha
       \alpha_{22}) v_2 +
        \cdots + (\alpha_{1n} + \alpha \alpha_{2n})v_n \\
      \alpha_{21}v_1 + \alpha_{22}v_2 + \cdots + \alpha_{2n}v_n\\
      \vdots\\
      \alpha_{m1}v_1 + \alpha_{m2}v_2 + \cdots + \alpha_{mn}v_n 
    \end{pmatrix}
    \\
    &amp; = &amp;
    \begin{pmatrix}
    (\alpha_{11}v_1 + \alpha_{12}v_2 + \cdots + \alpha_{1n}v_n) + \alpha
      (\alpha_{21}v_1 + \alpha_{22}v_2 + \cdots + \alpha_{2n}v_n) \\
    \alpha_{21}v_1 + \alpha_{22}v_2 + \cdots + \alpha_{2n}v_n \\
    \vdots\\
    \alpha_{m1}v_1 + \alpha_{m2}v_2 + \cdots + \alpha_{mn}v_n
    \end{pmatrix}\\
    &amp; = &amp;
    \vec{0}
  \end{aligned}\]</span> again by the above. ◻</p>
</div>
<h2 id="algorithm-1-show-that-a-set-of-vectors-is-linearly-independent">Algorithm 1: Show that a set of vectors is linearly (in)dependent</h2>
<div class="algorithm">
<p><span id="HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1" label="HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1"></span> Show that the collection <span class="math display">\[\mathscr{A} = 
    \left\{
      \begin{pmatrix}
      v_{1,1}  \\
      v_{2, 1} \\
      \vdots\\
      v_{n, 1}
    \end{pmatrix}, 
    \ldots,
    \begin{pmatrix}
      v_{1, m}  \\
      v_{2, m} \\
      \vdots\\
      v_{n, m}
    \end{pmatrix}
    \right\}
    \subseteq F ^ n\]</span> of vectors is, or is not, linearly independent.</p>
<ol type="1">
<li><p>Make an <span class="math inline">\(n\times m\)</span> matrix whose columns are the vectors in <span class="math inline">\(\mathscr{A}\)</span>: <span class="math display">\[\begin{pmatrix}
              v_{1, 1} &amp; v_{1, 2} &amp; \cdots &amp; v_{1, m} \\
              v_{2, 1} &amp; v_{2, 2} &amp; \cdots &amp; v_{2, m} \\
              \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots   \\
              v_{n, 1} &amp; v_{n, 2} &amp; \cdots &amp; v_{n, m}
            \end{pmatrix}\]</span> or whose rows are the vectors in <span class="math inline">\(\mathscr{A}\)</span>, in other words, the <span class="math inline">\(m \times n\)</span> matrix that is the transpose of the matrix above: <span class="math display">\[\begin{pmatrix}
              v_{1, 1} &amp; v_{2, 1} &amp; \cdots &amp; v_{n, 1} \\
              v_{1, 2} &amp; v_{2, 2} &amp; \cdots &amp; v_{n, 2} \\
              \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots   \\
              v_{1, m} &amp; v_{2, m} &amp; \cdots &amp; v_{n, m}
            \end{pmatrix}\]</span></p></li>
<li><p>Perform elementary row operations or elementary column operations to the matrix from step (1) until it is in row or column echelon form. Note that it does not matter if you used rows or columns in step (1), you can use either row or column operations.</p></li>
<li><p>If the number of non-zero rows in the row echelon form equals <span class="math inline">\(|\mathscr{A}| = m\)</span>, then <span class="math inline">\(\mathscr{A}\)</span> is linearly independent. If the number of non-zero columns in the column echelon form equals <span class="math inline">\(|\mathscr{A}| = m\)</span>, then <span class="math inline">\(\mathscr{A}\)</span> is linearly independent.</p></li>
</ol>
</div>
<div class="thm">
<p><span id="HUGO_REPLACE_thm-algorithm-1_Theorem-3.3.2" label="HUGO_REPLACE_thm-algorithm-1_Theorem-3.3.2"></span> <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1">Algorithm 3.3.1</a> is valid.</p>
</div>
<div class="proof">
<p><em>Proof.</em> [Omitted from the course.] Suppose that we enter the vectors in <span class="math inline">\(\mathscr{A}\)</span> as columns in a matrix <span class="math inline">\(A\)</span> in part (1), and perform elementary column operations in part (2) to obtain a matrix <span class="math inline">\(E\)</span> in column echelon form. Then, by <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_prop-row-equiv_Proposition-3.2.4">Proposition 3.2.4</a>, <span class="math inline">\(A\)</span> and <span class="math inline">\(E\)</span> are column-equivalent, and so <span class="math inline">\(\operatorname{Col}(A) = \operatorname{Col}(E)\)</span>. Hence, by <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_prop-row-echelon-basis_Proposition-3.2.6">Proposition 3.2.6</a>, the non-zero columns in <span class="math inline">\(E\)</span> are a basis for <span class="math inline">\(\operatorname{Col}(E)\)</span>. But <span class="math inline">\(\operatorname{Col}(A) = \operatorname{Span}(\mathscr{A})\)</span> by definition and <span class="math inline">\(\mathscr{A}\)</span> is linearly independent if and only if the <span class="math inline">\(\operatorname{dim}\operatorname{Span}(\mathscr{A}) = |\mathscr{A}|\)</span> if and only if the number of non-zero columns in <span class="math inline">\(E\)</span>, which equals <span class="math inline">\(\operatorname{dim}\operatorname{Col}(E) = \operatorname{dim}\operatorname{Span}(\mathscr{A})  = |\mathscr{A}|\)</span>.</p>
<p>If we perform row operations rather than column operations in <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1">Algorithm 3.3.1</a>(2) or obtain the row echelon form for <span class="math inline">\(A\)</span>, then we must use the fact that the row and column rank of a matrix (see Theorem 7.5.3) are equal to prove that <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1">Algorithm 3.3.1</a> is valid. ◻</p>
</div>
<div class="exampjupyter">
<p>Is the collection <span class="math display">\[\mathscr{A} =
    \left\{
    \begin{pmatrix} 2 \\ 1 \\ 0 \\ 0 \end{pmatrix},
    \begin{pmatrix} 1 \\ 1 \\ 1 \\ 0 \end{pmatrix},
    \begin{pmatrix} 1 \\ 0 \\ 1 \\ 1 \end{pmatrix}
    \right\}\]</span> a linearly independent subset of <span class="math inline">\(\mathbb{R} ^ 4\)</span>?</p>
</div>
<div class="solution">
<p>We must put the vectors in <span class="math inline">\(\mathscr{A}\)</span> in a matrix <span class="math inline">\(A\)</span>, then perform elementary operations to <span class="math inline">\(A\)</span> to put it into echelon form. The set <span class="math inline">\(\mathscr{A}\)</span> is linearly independent if and only if the number of non-zero rows in the echelon form of <span class="math inline">\(A\)</span> is <span class="math inline">\(3\)</span>.</p>
<p>Do we enter the vectors as rows or columns of <span class="math inline">\(A\)</span>? Do we perform row operations or column operations? What is valid here exactly? The argument in <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_thm-algorithm-1_Theorem-3.3.2">Theorem 3.3.2</a> says that it does not matter, and that all approaches are valid here.</p>
<p>Set <span class="math inline">\(A\)</span> to be the matrix with rows equal to <span class="math inline">\(\mathscr{A}\)</span>: <span class="math display">\[A =
    \begin{pmatrix}
      2 &amp; 1 &amp; 0 &amp; 0 \\
      1 &amp; 1 &amp; 1 &amp; 0 \\
      1 &amp; 0 &amp; 1 &amp; 1
    \end{pmatrix}.\]</span> We perform elementary column operations to obtain the column-echelon form of <span class="math inline">\(A\)</span>: <span class="math display">\[\begin{array}{rcll}
      \begin{pmatrix}
        2 &amp; 1 &amp; 0 &amp; 0 \\
        1 &amp; 1 &amp; 1 &amp; 0 \\
        1 &amp; 0 &amp; 1 &amp; 1
      \end{pmatrix}
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        2 &amp; 0 &amp; 1 &amp; 0 \\
        1 &amp; 1 &amp; 1 &amp; 0 \\
        1 &amp; 1 &amp; 0 &amp; 1
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        c_2 \longleftrightarrow c_3 \\
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        2 &amp; 0 &amp; 0 &amp; 1 \\
        1 &amp; 1 &amp; 0 &amp; 1 \\
        1 &amp; 1 &amp; 1 &amp; 0
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        c_3 \longleftrightarrow c_4 \\
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        2 &amp; 0 &amp; 0 &amp; 1 \\
        0 &amp; 1 &amp; 0 &amp; 1 \\
        0 &amp; 0 &amp; 1 &amp; 0
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        c_1 \longrightarrow c_1 - c_2 \\
        c_2 \longrightarrow c_2 - c_3
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        2 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 1 &amp; 0
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        c_4 \longrightarrow 2c_4 - c_1 - 2c_2.
      \end{array}
    \end{array}\]</span> The number of non-zero columns in the column echelon form of <span class="math inline">\(A\)</span> is <span class="math inline">\(3 =  |\mathscr{A}|\)</span> and so <span class="math inline">\(\mathscr{A}\)</span> is linearly independent.</p>
</div>
<div class="omittedexamp">
<p>Determine whether the set <span class="math inline">\(\{ x+x^{2}, 1-2x^{2}, 3+6x \}\)</span> is linearly independent in the vector space <span class="math inline">\(\mathcal{P}\)</span> of all real polynomials.</p>
</div>
<div class="solution">
<p>We solve <span class="math display">\[\alpha(x+x^{2}) + \beta(1-2x^{2}) + \gamma(3+6x) = 0;\]</span> that is, <span class="math display">\[\label{eq:lindep-example}
    (\beta+3\gamma) + (\alpha+6\gamma)x + (\alpha-2\beta)x^{2} = 0.\]</span> Equating coefficients yields the system of equations <span class="math display">\[\begin{aligned}
    \beta + 3\gamma          &amp; = 0 \\
    \alpha \qquad\, +6\gamma &amp; = 0 \\
    \alpha-2\beta \qquad\,   &amp; =0;
  \end{aligned}\]</span> that is, <span class="math display">\[\begin{pmatrix}
      0 &amp; 1  &amp; 3 \\
      1 &amp; 0  &amp; 6 \\
      1 &amp; -2 &amp; 0
    \end{pmatrix}
    \begin{pmatrix} \alpha \\ \beta \\ \gamma \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}.\]</span> A sequence of row operations (<span class="smallcaps">Check!</span>) converts this to <span class="math display">\[\begin{pmatrix}
      1 &amp; -2 &amp; 0 \\
      0 &amp; 1  &amp; 3 \\
      0 &amp; 0  &amp; 0
    \end{pmatrix} \begin{pmatrix} \alpha \\ \beta \\ \gamma \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}.\]</span> Hence the original equation is equivalent to <span class="math display">\[\begin{aligned}
    \alpha - 2\beta \qquad\, &amp; = 0  \\
    \beta + 3\gamma          &amp; = 0.
  \end{aligned}\]</span> Since there are fewer equations remaining than the number of variables, there is a non-zero solution. For example, if we set <span class="math inline">\(\gamma = 1\)</span>, then <span class="math inline">\(\beta = -3\gamma = -3\)</span> and <span class="math inline">\(\alpha  = 2\beta = -6\)</span>. Hence the set <span class="math inline">\(\{ x+x^{2}, 1-2x^{2}, 3+6x \}\)</span> is <em>linearly dependent</em>.</p>
</div>
<div class="omittedexamp">
<p>Is the collection: <span class="math display">\[\mathscr{A} =
    \left\{
    \begin{pmatrix} -61 \\ -6 \\ -60 \\ -16 \end{pmatrix},
    \begin{pmatrix} 91 \\ 12 \\ 46 \\ 58 \end{pmatrix},
    \begin{pmatrix} 31 \\ -97 \\ 54 \\ -48 \end{pmatrix}
    \begin{pmatrix} 0 \\ 97 \\ 20 \\ 22 \end{pmatrix}
    \right\}\]</span> a linearly independent subset of <span class="math inline">\(\mathbb{R} ^ 4\)</span>?</p>
</div>
<div class="solution">
<p>TODO</p>
</div>
<h2 id="algorithm-2-find-the-dimension-of-a-subspace">Algorithm 2: Find the dimension of a subspace</h2>
<div class="algorithm">
<p><span id="HUGO_REPLACE_algorithm-dim-of-subspace_Algorithm-3.4.1" label="HUGO_REPLACE_algorithm-dim-of-subspace_Algorithm-3.4.1"></span> Find <span class="math inline">\(\operatorname{dim}\operatorname{Span}(\mathscr{A})\)</span> where <span class="math inline">\(\mathscr{A}\)</span> is: <span class="math display">\[\mathscr{A} = \left\{\begin{pmatrix} v_{1,1} \\ v_{2, 1} \\ \vdots \\ v_{n, 1}
      \end{pmatrix}, \ldots,
    \begin{pmatrix} v_{1,m} \\ v_{2, m} \\ \vdots \\ v_{n, m}
  \end{pmatrix}\right\}
    \subseteq F ^ n.\]</span></p>
<ol type="1">
<li><p>Make an <span class="math inline">\(n\times m\)</span> matrix whose columns are the vectors in <span class="math inline">\(\mathscr{A}\)</span> or whose rows are the vectors in <span class="math inline">\(\mathscr{A}\)</span>; this is identical to <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1">Algorithm 3.3.1</a>(1).</p></li>
<li><p>Perform elementary row operations or elementary column operations to the matrix from step (1) until it is in row or column echelon form; this is identical to <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1">Algorithm 3.3.1</a>(2).</p></li>
<li><p>The number of non-zero rows in the row echelon form of the matrix from step (1) is the dimension of the subspace spanned by <span class="math inline">\(\mathscr{A}\)</span>. The number of non-zero columns in the column echelon form of the matrix from step (1) is the dimension of the subspace spanned by <span class="math inline">\(\mathscr{A}\)</span>.</p></li>
</ol>
</div>
<div class="thm">
<p><span id="HUGO_REPLACE_thm-algorithm-2_Theorem-3.4.2" label="HUGO_REPLACE_thm-algorithm-2_Theorem-3.4.2"></span> <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-dim-of-subspace_Algorithm-3.4.1">Algorithm 3.4.1</a> is valid.</p>
</div>
<div class="proof">
<p><em>Proof.</em> In the proof of <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_thm-algorithm-1_Theorem-3.3.2">Theorem 3.3.2</a> we showed that if <span class="math inline">\(E\)</span> is the column echelon form of the matrix <span class="math inline">\(A\)</span> with columns equal to the vectors in <span class="math inline">\(\mathscr{A}\)</span>, then <span class="math inline">\(\operatorname{dim} \operatorname{Col}(E) = \operatorname{dim} \operatorname{Span}(\mathscr{A})\)</span> and that <span class="math inline">\(\operatorname{dim} \operatorname{Col}(E)\)</span> is the number of non-zero columns in <span class="math inline">\(E\)</span>. ◻</p>
</div>
<div class="exampjupyter">
<p>Find the dimension of the subspace of <span class="math inline">\(\mathbb{R} ^ 3\)</span> spanned by the vectors <span class="math display">\[\begin{pmatrix}
      -2 \\
      2 \\
      0 \\
    \end{pmatrix},
    \begin{pmatrix}
      -1 \\
      0 \\
      0 \\
    \end{pmatrix},
    \begin{pmatrix}
      1 \\
      -3 \\
      1 \\
    \end{pmatrix}.\]</span></p>
</div>
<div class="solution">
<p>We enter the vectors above as the columns in a matrix <span class="math inline">\(A\)</span>: <span class="math display">\[A =
    \begin{pmatrix}
      -2 &amp; -1 &amp; 1  \\
      2  &amp; 0  &amp; -3 \\
      0  &amp; 0  &amp; 1
    \end{pmatrix}\]</span> and perform elementary row operations to find an row echelon matrix equivalent to <span class="math inline">\(A\)</span>: <span class="math display">\[\begin{array}{rcll}
      \begin{pmatrix}
        -2 &amp; -1 &amp; 1  \\
        2  &amp; 0  &amp; -3 \\
        0  &amp; 0  &amp; 1
      \end{pmatrix}
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        -2 &amp; -1 &amp; 1  \\
        0  &amp; -1 &amp; -2 \\
        0  &amp; 0  &amp; 1
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_2 \longrightarrow r_1 + r_2. \\
      \end{array}
      \\
    \end{array}\]</span> Since the matrix: <span class="math display">\[\begin{pmatrix}
      -2 &amp; -1 &amp; 1  \\
      0  &amp; -1 &amp; -2 \\
      0  &amp; 0  &amp; 1
    \end{pmatrix}\]</span> is in row-echelon form, it follows that the dimension of the space spanned by the vectors is <span class="math inline">\(3\)</span>.</p>
</div>
<div class="exampjupyter">
<p>Find <span class="math inline">\(\operatorname{dim}\operatorname{Span}(\mathscr{A})\)</span> where <span class="math display">\[\mathscr{A} =
    \left\{
      \begin{pmatrix} 0 \\
        0 \\
        0 \\
        0 \\
      \end{pmatrix},
      \begin{pmatrix} 1 \\
        0 \\
        1 \\
        -1 \\
      \end{pmatrix},
      \begin{pmatrix} 0 \\
        -1 \\
        0 \\
        0 \\
      \end{pmatrix},
      \begin{pmatrix} 2 \\
        -1 \\
        0 \\
        2 \\
      \end{pmatrix}
    \right\}\subseteq \mathbb{R} ^ 4.\]</span></p>
</div>
<div class="solution">
<p>We enter the vectors in <span class="math inline">\(\mathscr{A}\)</span> as the rows in a matrix <span class="math inline">\(A\)</span>: <span class="math display">\[A =
    \begin{pmatrix}
      0 &amp; 0  &amp; 0 &amp; 0  \\
      1 &amp; 0  &amp; 1 &amp; -1 \\
      0 &amp; -1 &amp; 0 &amp; 0  \\
      2 &amp; -1 &amp; 0 &amp; 2
    \end{pmatrix}\]</span> and perform elementary row operations to find an row echelon matrix equivalent to <span class="math inline">\(A\)</span>: <span class="math display">\[\begin{array}{rcll}
      \begin{pmatrix}
        0 &amp; 0  &amp; 0 &amp; 0  \\
        1 &amp; 0  &amp; 1 &amp; -1 \\
        0 &amp; -1 &amp; 0 &amp; 0  \\
        2 &amp; -1 &amp; 0 &amp; 2
      \end{pmatrix}
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        1 &amp; 0  &amp; 1 &amp; -1 \\
        0 &amp; -1 &amp; 0 &amp; 0  \\
        2 &amp; -1 &amp; 0 &amp; 2  \\
        0 &amp; 0  &amp; 0 &amp; 0  \\
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_1 \longrightarrow r_2 \longrightarrow r_3 \longrightarrow r_4
        \longrightarrow r_1 \\
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        1 &amp; 0  &amp; 1  &amp; -1 \\
        0 &amp; -1 &amp; 0  &amp; 0  \\
        0 &amp; -1 &amp; -2 &amp; 4  \\
        0 &amp; 0  &amp; 0  &amp; 0  \\
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_3 \longrightarrow r_3 - 2r_1 \\
      \end{array} \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        1 &amp; 0  &amp; 1  &amp; -1 \\
        0 &amp; -1 &amp; 0  &amp; 0  \\
        0 &amp; 0  &amp; -2 &amp; 4  \\
        0 &amp; 0  &amp; 0  &amp; 0  \\
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_3 \longrightarrow r_3 - r_2 \\
      \end{array}
    \end{array}\]</span> It follows that <span class="math inline">\(\operatorname{dim}\operatorname{Span}(\mathscr{A}) = 3\)</span>.</p>
</div>
<h2 id="algorithm-3-find-a-basis-for-a-subspace">Algorithm 3: Find a basis for a subspace</h2>
<div class="algorithm">
<p><span id="HUGO_REPLACE_algorithm-subspace-basis_Algorithm-3.5.1" label="HUGO_REPLACE_algorithm-subspace-basis_Algorithm-3.5.1"></span> Find a basis for the subspace <span class="math inline">\(\operatorname{Span}(\mathscr{A})\)</span> where <span class="math inline">\(\mathscr{A}\)</span> is: <span class="math display">\[\mathscr{A} = \left\{\begin{pmatrix} v_{1,1} \\ v_{2, 1} \\ \vdots \\ v_{n, 1}
      \end{pmatrix}, \ldots,
    \begin{pmatrix} v_{1,m} \\  v_{2, m}\\\vdots \\vec{v}_{n, m} \end{pmatrix}  \right\}
    \subseteq F ^ n.\]</span></p>
<ol type="1">
<li><p>Make an <span class="math inline">\(n\times m\)</span> matrix whose columns are the vectors in <span class="math inline">\(\mathscr{A}\)</span> or whose rows are the vectors in <span class="math inline">\(\mathscr{A}\)</span>; this is identical to <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-lin-independence_Algorithm-3.3.1">Algorithm 3.3.1</a>(1).</p></li>
<li><p>If in step (1) you entered <span class="math inline">\(\mathscr{A}\)</span> as rows, then perform elementary row operations to obtain the matrix in row echelon form. If in step (1) you entered <span class="math inline">\(\mathscr{A}\)</span> as columns, then perform elementary column operations to obtain the matrix in column echelon form.</p></li>
<li><p>The non-zero rows in the row echelon form of the matrix from step (1) is a basis for the row-space of that matrix, which is also the subspace spanned by <span class="math inline">\(\mathscr{A}\)</span>.</p>
<p>The non-zero columns in the column echelon form of the matrix from step (1) is a basis for the column-space of that matrix, which is also the subspace spanned by <span class="math inline">\(\mathscr{A}\)</span>.</p></li>
</ol>
</div>
<div class="thm">
<p><span id="HUGO_REPLACE_thm-algorithm-3_Theorem-3.5.2" label="HUGO_REPLACE_thm-algorithm-3_Theorem-3.5.2"></span> <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-subspace-basis_Algorithm-3.5.1">Algorithm 3.5.1</a> is valid.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Suppose that the vectors in <span class="math inline">\(\mathscr{A}\)</span> are entered as the rows in a matrix <span class="math inline">\(A\)</span>. Then part (2) of the algorithm says that we must perform elementary row operations to <span class="math inline">\(A\)</span> to obtain a matrix <span class="math inline">\(E\)</span> in row-echelon form for <span class="math inline">\(A\)</span>. It follows by <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_prop-row-equiv_Proposition-3.2.4">Proposition 3.2.4</a> that <span class="math inline">\(\operatorname{Row}(A) =  \operatorname{Row}(E)\)</span> and by <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_prop-row-echelon_Proposition-3.2.2">Proposition 3.2.2</a> that the non-zero rows of <span class="math inline">\(E\)</span> form a basis for <span class="math inline">\(\operatorname{Row}(E)\)</span>.</p>
<p>The proof using columns instead of rows is similar. ◻</p>
</div>
<div class="omittedexampjupyter">
<p><span id="HUGO_REPLACE_omittedexamp-5a_Example-3.5A" label="HUGO_REPLACE_omittedexamp-5a_Example-3.5A"></span> Let <span class="math display">\[\vec{v}_{1} = \begin{pmatrix} 1 \\
      -1 \\
      0 \\
      3 \\
    \end{pmatrix}, \quad
    \vec{v}_{2} = \begin{pmatrix} 2 \\
      1 \\
      1 \\
      0 \\
    \end{pmatrix},  \quad
    \vec{v}_{3} = \begin{pmatrix} 0 \\
      3 \\
      1 \\
      -6 \\
    \end{pmatrix}, \quad
    \vec{v}_{4} = \begin{pmatrix} 0 \\
      1 \\
      0 \\
      -1 \\
    \end{pmatrix}, \quad
    \vec{v}_{5} = \begin{pmatrix} -1 \\
      1 \\
      -1 \\
      0 \\
    \end{pmatrix}\]</span> and let <span class="math inline">\(U\)</span> be the subspace of <span class="math inline">\(\mathbb{R}^{4}\)</span> spanned by the set <span class="math inline">\(\mathscr{A} = \{  \vec{v}_{1}, \vec{v}_{2}, \vec{v}_{3}, \vec{v}_{4}, \vec{v}_{5}  \}\)</span>. Find a basis <span class="math inline">\(\mathscr{B}\)</span> for <span class="math inline">\(U\)</span> and hence determine the dimension of <span class="math inline">\(U\)</span>.</p>
</div>
<div class="solution">
<p>We put the vectors <span class="math inline">\(\vec{v}_1\)</span>, <span class="math inline">\(\vec{v}_2\)</span>, <span class="math inline">\(\vec{v}_3\)</span>, <span class="math inline">\(\vec{v}_4\)</span>, and <span class="math inline">\(\vec{v}_5\)</span> as columns in the matrix: <span class="math display">\[A =
    \begin{pmatrix}
      1  &amp; 2 &amp; 0  &amp; 0  &amp; -1 \\
      -1 &amp; 1 &amp; 3  &amp; 1  &amp; 1  \\
      0  &amp; 1 &amp; 1  &amp; 0  &amp; -1 \\
      3  &amp; 0 &amp; -6 &amp; -1 &amp; 0
    \end{pmatrix}.\]</span> We apply column operation to <span class="math inline">\(A\)</span> as follows: <span class="math display">\[\begin{array}{rcll}
      \begin{pmatrix}
        1  &amp; 2 &amp; 0  &amp; 0  &amp; -1 \\
        -1 &amp; 1 &amp; 3  &amp; 1  &amp; 1  \\
        0  &amp; 1 &amp; 1  &amp; 0  &amp; -1 \\
        3  &amp; 0 &amp; -6 &amp; -1 &amp; 0
      \end{pmatrix}
       &amp; \longrightarrow          &amp;
      \begin{pmatrix}
        1 &amp; 2 &amp; 0  &amp; 0  &amp; -1 \\
        2 &amp; 1 &amp; 3  &amp; 1  &amp; 1  \\
        0 &amp; 1 &amp; 1  &amp; 0  &amp; -1 \\
        0 &amp; 0 &amp; -6 &amp; -1 &amp; 0
      \end{pmatrix}
       &amp; c_1 \to c_1 + 3c_4         \\
       &amp; \longrightarrow          &amp;
      \begin{pmatrix}
        1 &amp; 1 &amp; 0  &amp; 0  &amp; -1 \\
        2 &amp; 2 &amp; 3  &amp; 1  &amp; 1  \\
        0 &amp; 0 &amp; 1  &amp; 0  &amp; -1 \\
        0 &amp; 0 &amp; -6 &amp; -1 &amp; 0
      \end{pmatrix}
       &amp; c_2 \to c_2 + c_5          \\
       &amp; \longrightarrow          &amp;
      \begin{pmatrix}
        0 &amp; 1 &amp; 0  &amp; 0  &amp; -1 \\
        0 &amp; 2 &amp; 3  &amp; 1  &amp; 1  \\
        0 &amp; 0 &amp; 1  &amp; 0  &amp; -1 \\
        0 &amp; 0 &amp; -6 &amp; -1 &amp; 0
      \end{pmatrix}
       &amp; c_1 \to c_1 - c_2          \\
       &amp; \longrightarrow          &amp;
      \begin{pmatrix}
        0 &amp; 1 &amp; -1 &amp; 0  &amp; -1 \\
        0 &amp; 2 &amp; -2 &amp; 1  &amp; 1  \\
        0 &amp; 0 &amp; 0  &amp; 0  &amp; -1 \\
        0 &amp; 0 &amp; 0  &amp; -1 &amp; 0
      \end{pmatrix}
       &amp; c_3 \to c_3 - 6c_4 + c_5   \\
       &amp; \longrightarrow          &amp;
      \begin{pmatrix}
        0 &amp; 1 &amp; 0 &amp; 0  &amp; -1 \\
        0 &amp; 2 &amp; 0 &amp; 1  &amp; 1  \\
        0 &amp; 0 &amp; 0 &amp; 0  &amp; -1 \\
        0 &amp; 0 &amp; 0 &amp; -1 &amp; 0
      \end{pmatrix}
       &amp; c_3 \to c_3 + c_2.
    \end{array}\]</span> At this point, it is more or less clear that the non-zero columns of the matrix: <span class="math display">\[\vec{w}_1 = \begin{pmatrix} 1 \\ 2 \\ 0 \\ 0 \end{pmatrix}, \quad
    \vec{w}_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ -1 \end{pmatrix}, \quad
    \vec{w}_3 = \begin{pmatrix} -1 \\ 1 \\ -1 \\ 0 \end{pmatrix}\]</span> are linearly independent, but let’s prove it anyway. Suppose that <span class="math inline">\(\alpha \vec{w}_1 + \beta \vec{w}_2 + \gamma \vec{w}_3 = \vec{0}\)</span> for some <span class="math inline">\(\alpha, \beta, \gamma \in \mathbb{R}\)</span>. Then <span class="math display">\[\begin{aligned}
    \alpha - \gamma &amp; = &amp; 0 \\
    2\alpha + \beta + \gamma &amp; = &amp; 0 \\
    -\gamma &amp; = &amp; 0 \\
    -\beta  &amp; = &amp; 0
  \end{aligned}\]</span> and so <span class="math inline">\(\alpha = \beta = \gamma = 0\)</span>, and the vectors <span class="math inline">\(\vec{w}_1\)</span>, <span class="math inline">\(\vec{w}_2\)</span>, and <span class="math inline">\(\vec{w}_3\)</span> are linearly independent. It follows from <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-subspace-basis_Algorithm-3.5.1">Algorithm 3.5.1</a> that <span class="math inline">\(\{\vec{w}_1, \vec{w}_2, \vec{w}_3\}\)</span> is a basis for <span class="math inline">\(U\)</span> and that <span class="math inline">\(\operatorname{dim} U = 3\)</span>.</p>
<p>It is possible to double check that <span class="math inline">\(\operatorname{Span}(\vec{w}_1, \vec{w}_2, \vec{w}_3) = U\)</span> by showing that <span class="math inline">\(\vec{v}_1, \vec{v}_2, \vec{v}_3, \vec{v}_4, \vec{v}_5\in\operatorname{Span}(\vec{w}_1, \vec{w}_2, \vec{w}_3)\)</span>. Since <span class="math inline">\(\vec{v}_4 =  \vec{w}_2\)</span> and <span class="math inline">\(\vec{v}_5 = \vec{w}_3\)</span>, it suffices to show that <span class="math inline">\(\vec{v}_1, \vec{v}_2, \vec{v}_3\in\operatorname{Span}(\vec{w}_1, \vec{w}_2, \vec{w}_3)\)</span>. This follows because: <span class="math display">\[\begin{aligned}
    \vec{v}_1 &amp; = &amp; \begin{pmatrix} 1 \\ -1 \\ 0 \\ 3 \end{pmatrix} = \vec{w}_1 - 3 \vec{w}_2 \\
    \vec{v}_2 &amp; = &amp; \begin{pmatrix} 2 \\ 1 \\ 1 \\ 0 \end{pmatrix}  = \vec{w}_1 - \vec{w}_3 \\
    \vec{v}_3 &amp; = &amp; \begin{pmatrix} 0 \\ 3 \\ 1 \\ -6 \end{pmatrix} = -\vec{w}_1 + 6\vec{w}_2 - \vec{w}_3,
  \end{aligned}\]</span> as required.</p>
</div>
<h2 id="algorithm-4-find-a-linear-combination-of-vectors-equal-a-given-vector">Algorithm 4: Find a linear combination of vectors equal a given vector</h2>
<div class="algorithm">
<p><span id="HUGO_REPLACE_algorithm-linear-combo_Algorithm-3.6.1" label="HUGO_REPLACE_algorithm-linear-combo_Algorithm-3.6.1"></span> If <span class="math display">\[\mathscr{A} = \left\{\vec{v}_1=\begin{pmatrix} v_{1,1} \\ v_{2, 1} \\ \vdots
      \\v_{n, 1} \end{pmatrix}, \ldots,
      \vec{v}_m=\begin{pmatrix} v_{1,m} \\ v_{2, m} \\ \vdots \\v_{n, m}
    \end{pmatrix} \right\}
    \subseteq F ^ n\]</span> and <span class="math display">\[\vec{u} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} \in \operatorname{Span}(\mathscr{A}),\]</span> then find a linear combination of the vectors in <span class="math inline">\(\mathscr{A}\)</span> that equals <span class="math inline">\(u\)</span>.</p>
<ol type="1">
<li><p>Make an <span class="math inline">\(n\times (m + 1)\)</span> matrix <span class="math inline">\(A\)</span> whose first <span class="math inline">\(m\)</span> columns are the vectors in <span class="math inline">\(\mathscr{A}\)</span> and whose last column is <span class="math inline">\(-\vec{u}\)</span> or an <span class="math inline">\((m + 1)\times  n\)</span> matrix whose first <span class="math inline">\(m\)</span> rows are the vectors in <span class="math inline">\(\mathscr{A}\)</span> and whose last row is <span class="math inline">\(-\vec{u}\)</span> (transposed). In other words, either <span class="math display">\[A =
            \begin{pmatrix}
              v_{1, 1} &amp; v_{1, 2} &amp; \cdots &amp; v_{1, m} &amp; -u_1   \\
              v_{2, 1} &amp; v_{2, 2} &amp; \cdots &amp; v_{2, m} &amp; -u_2   \\
              \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots   &amp; \vdots \\
              v_{n, 1} &amp; v_{n, 2} &amp; \cdots &amp; v_{n, m} &amp; -u_n
            \end{pmatrix}
            \quad\text{or}\quad
            A =
            \begin{pmatrix}
              v_{1, 1} &amp; v_{2, 1} &amp; \cdots &amp; v_{n, 1} \\
              v_{1, 2} &amp; v_{2, 2} &amp; \cdots &amp; v_{n, 2} \\
              \vdots   &amp; \vdots   &amp; \ddots &amp; \vdots   \\
              v_{1, m} &amp; v_{2, m} &amp; \cdots &amp; v_{n, m} \\
              -u_1     &amp; -u_2     &amp; \cdots &amp; -u_n
            \end{pmatrix}.\]</span></p></li>
<li><p>If in step (1) you entered <span class="math inline">\(\mathscr{A}\)</span> as rows, then perform elementary column operations to obtain the matrix <span class="math inline">\(E\)</span> in column echelon form. If in step (1) you entered <span class="math inline">\(\mathscr{A}\)</span> as columns, then perform elementary row operations to obtain the matrix <span class="math inline">\(E\)</span> in row echelon form.</p></li>
<li><p>Suppose that we entered <span class="math inline">\(\mathscr{A}\)</span> as the columns of <span class="math inline">\(A\)</span> and that <span class="math display">\[\vec{\alpha} = \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \vdots \\\alpha_{m + 1} \end{pmatrix}
            \in F ^ {m + 1}\]</span> is such that <span class="math display">\[E\vec{\alpha} = \vec{0}.\]</span> This gives a homogeneous system of linear equations in the variables <span class="math inline">\(\alpha_{i}\)</span>, which can be solved for the variables <span class="math inline">\(\alpha_1, \ldots, \alpha_{m + 1}\)</span>. In particular, you have found a specific vector <span class="math inline">\(\vec{\alpha}\)</span> such that <span class="math inline">\(E\vec{\alpha} = \vec{0}\)</span>.</p>
<p>If you entered <span class="math inline">\(\mathscr{A}\)</span> as the columns of <span class="math inline">\(A\)</span>, then the process is similar.</p></li>
<li><p>By <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_thm-row-ops-preserve-null-space_Theorem-3.2.7">Theorem 3.2.7</a>, since <span class="math inline">\(A\)</span> and <span class="math inline">\(E\)</span> are row-equivalent, <span class="math inline">\(A \vec{\alpha} = \vec{0}\)</span> also. In particular, <span class="math display">\[\alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 + \cdots + \alpha_m\vec{v}_m -
            \alpha_{m + 1} \vec{u} = \vec{0},\]</span> and so rearranging, we obtain, <span class="math display">\[\vec{u} = \frac{\alpha_1}{\alpha_{m + 1}}\vec{v}_1 +
            \frac{\alpha_2}{\alpha_{m + 1}}\vec{v}_2 + \cdots +
            \frac{\alpha_m}{\alpha_{m + 1}}\vec{v}_m.\]</span></p></li>
</ol>
</div>
<p>That <a href="https://jdbm.me/mt3501-lnotes/03-algorithms-to-live-by/#HUGO_REPLACE_algorithm-dim-of-subspace_Algorithm-3.4.1">Algorithm 3.4.1</a> is valid, was shown in the statement of the algorithm.</p>
<div class="exampjupyter">
<p>Suppose that <span class="math display">\[\vec{v}_1 = 
    \begin{pmatrix} 
      -2 \\
      0 \\
      3 \\
      0 \\
    \end{pmatrix},\
    \vec{v}_2 = 
    \begin{pmatrix} 
      -1 \\
      1 \\
      -3 \\
      0 \\
    \end{pmatrix},\
    \vec{v}_3 = 
    \begin{pmatrix} 
      1 \\
      0 \\
      -1 \\
      3 \\
    \end{pmatrix},\
    \vec{v}_4 = 
    \begin{pmatrix} 
      1 \\
      0 \\
      -1 \\
      0 \\
    \end{pmatrix} \in \mathbb{R} ^ 4.\]</span> Write <span class="math display">\[\vec{u} = \begin{pmatrix} 0 \\
 0 \\
 -1 \\
 2 \\
 \end{pmatrix} \in \mathbb{R} ^ 4\]</span> as a linear combination of <span class="math inline">\(\vec{v}_1\)</span>, <span class="math inline">\(\vec{v}_2\)</span>, <span class="math inline">\(\vec{v}_3\)</span>, and <span class="math inline">\(\vec{v}_4\)</span>.</p>
</div>
<div class="solution">
<p>We write <span class="math inline">\(\vec{v}_1\)</span>, <span class="math inline">\(\vec{v}_2\)</span>, <span class="math inline">\(\vec{v}_3\)</span>, <span class="math inline">\(\vec{v}_4\)</span>, and <span class="math inline">\(\vec{u}\)</span> as the columns in a matrix <span class="math inline">\(A\)</span> and perform elementary row operations to obtain a matrix <span class="math inline">\(E\)</span> that is in row-echelon form and is row-equivalent to <span class="math inline">\(A\)</span>: <span class="math display">\[\begin{array}{rcll}
      A =
      \begin{pmatrix}
        -2 &amp; -1 &amp; 1  &amp; 1  &amp; 0  \\
        0  &amp; 1  &amp; 0  &amp; 0  &amp; 0  \\
        3  &amp; -3 &amp; -1 &amp; -1 &amp; 1  \\
        0  &amp; 0  &amp; 3  &amp; 0  &amp; -2
      \end{pmatrix}
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        -6 &amp; -3 &amp; 3  &amp; 3  &amp; 0  \\
        0  &amp; 1  &amp; 0  &amp; 0  &amp; 0  \\
        6  &amp; -6 &amp; -2 &amp; -2 &amp; 2  \\
        0  &amp; 0  &amp; 3  &amp; 0  &amp; -2
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_1 \longrightarrow 3r_1 \\
        r_3 \longrightarrow 2r_3
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        -6 &amp; -3 &amp; 3 &amp; 3 &amp; 0  \\
        0  &amp; 1  &amp; 0 &amp; 0 &amp; 0  \\
        0  &amp; -9 &amp; 1 &amp; 1 &amp; 2  \\
        0  &amp; 0  &amp; 3 &amp; 0 &amp; -2
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_3 \longrightarrow r_1 + r_3
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        -6 &amp; -3 &amp; 3 &amp; 3 &amp; 0  \\
        0  &amp; 1  &amp; 0 &amp; 0 &amp; 0  \\
        0  &amp; 0  &amp; 1 &amp; 1 &amp; 2  \\
        0  &amp; 0  &amp; 3 &amp; 0 &amp; -2
      \end{pmatrix}
       &amp;
      \begin{array}{l}
        r_3 \longrightarrow 9r_2 + r_3
      \end{array}
      \\
       &amp; \longrightarrow &amp;
      \begin{pmatrix}
        -6 &amp; -3 &amp; 3 &amp; 3  &amp; 0  \\
        0  &amp; 1  &amp; 0 &amp; 0  &amp; 0  \\
        0  &amp; 0  &amp; 1 &amp; 1  &amp; 2  \\
        0  &amp; 0  &amp; 0 &amp; -3 &amp; -8
      \end{pmatrix}
      =
      E
       &amp;
      \begin{array}{l}
        r_4 \longrightarrow -3r_3 + r_4
      \end{array}
      \\
    \end{array}\]</span> So, if <span class="math display">\[\vec{\alpha} =
    \begin{pmatrix}
      \alpha_1 \\
      \alpha_2 \\
      \alpha_3 \\
      \alpha_4 \\
      \alpha_5
    \end{pmatrix}
    \in \mathbb{R} ^ 5\]</span> is such that <span class="math inline">\(E\vec{\alpha} = \vec{0}\)</span>, then <span class="math display">\[\begin{array}{rcrcrcrcrcl}
      -6\alpha_1 &amp; - &amp; 3\alpha_2 &amp; + &amp; 3\alpha_3 &amp; + &amp; 3\alpha_4 &amp;   &amp;
                 &amp; = &amp; 0                                               \\
                 &amp;   &amp; \alpha_2  &amp;   &amp;           &amp;   &amp;           &amp;   &amp;
                 &amp; = &amp; 0                                               \\
                 &amp;   &amp;           &amp;   &amp; \alpha_3  &amp; + &amp; \alpha_4  &amp; + &amp;
      2\alpha_5  &amp; = &amp; 0                                               \\
                 &amp;   &amp;           &amp;   &amp;           &amp; - &amp; 3\alpha_4 &amp; - &amp;
      8\alpha_5  &amp; = &amp; 0.                                              \\
    \end{array}\]</span> Hence <span class="math display">\[\alpha_2 = 0,
    \quad \alpha_4 = \frac{-8}{3}\alpha_5,
    \quad \text{and}
    \quad \alpha_3 = \frac{2}{3}\alpha_5.\]</span> If we choose <span class="math inline">\(\alpha_5 = 3\)</span>, then <span class="math inline">\(\alpha_2 = 0\)</span>, <span class="math inline">\(\alpha_3 = 2\)</span>, <span class="math inline">\(\alpha_4 = -8\)</span>, and so <span class="math inline">\(\alpha_1 = -3\)</span>. So, one possibility for <span class="math inline">\(\vec{\alpha}\)</span> is <span class="math display">\[\vec{\alpha} =
    \begin{pmatrix}
      -3 \\
      0  \\
      2  \\
      -8 \\
      3
    \end{pmatrix}.\]</span> [Aside: at this point it would be prudent to double-check that <span class="math inline">\(E\vec{v}  = \vec{0}\)</span> and <span class="math inline">\(A\vec{v} = \vec{0}\)</span>, I did this, I suggest you do too!] Hence <span class="math display">\[\alpha_1\vec{v}_1 + \alpha_2\vec{v}_2 + \alpha_3\vec{v}_3 + \alpha_4\vec{v}_4
    - \alpha_5\vec{u} = \vec{0}\]</span> and so <span class="math display">\[\vec{u} =    \frac{\alpha_1}{\alpha_5}\vec{v}_1
    + \frac{\alpha_2}{\alpha_5}\vec{v}_2
    + \frac{\alpha_3}{\alpha_5}\vec{v}_3
    + \frac{\alpha_4}{\alpha_5}\vec{v}_4
    = -\vec{v}_1 + \frac{2}{3}\vec{v}_3 - \frac{8}{3}\vec{v}_4.\]</span></p>
</div>
<h2 id="section-ultimate-guide">Rows versus columns, the ultimate guide</h2>
<p>You might have noticed by this point that we have been denoting vectors by columns rather than rows. For example, we write, <span class="math display">\[\begin{pmatrix} 3 \\ 1 \\ 0 \\ 0 \end{pmatrix}\]</span> rather than <span class="math display">\[(3\ 1\ 0\ 0).\]</span> We prefer column vectors to row vectors in this course for reasons related to linear transformations; we will discuss this in more detail in the next chapter.</p>
<p>Recall that from the start of this chapter that we said that there are 4 problems that you might be asked to solve that can be solved using Gaussian elimination:</p>
<ol type="1">
<li><p>Show that a collection <span class="math inline">\(\mathscr{A}\)</span> of vectors in a vector space <span class="math inline">\(V\)</span> is linearly independent or linearly dependent;</p></li>
<li><p>Find the dimension of a subspace <span class="math inline">\(W\)</span> spanned by some collection <span class="math inline">\(\mathscr{A}\)</span> of vectors;</p></li>
<li><p>Find a basis for a subspace <span class="math inline">\(W\)</span> spanned by some collection <span class="math inline">\(\mathscr{A}\)</span> of vectors;</p></li>
<li><p>Find a linear combination of vectors equal to some vector;</p></li>
</ol>







<p><a href="#">Back to top</a></p>
</body>
</html>
