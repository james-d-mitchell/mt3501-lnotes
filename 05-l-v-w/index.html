<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
   "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="en-uk" xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" href="data:;base64,iVBORw0KGgo=" />
    <link rel="stylesheet" href="../css/math.css">
    
    
    <title>MT3501 Lecture Notes | </title>
    <style type="text/css">
  body {
    font-size: 150%;
    font-family: muli,avenir,helvetica neue,helvetica,ubuntu,roboto,noto,segoe ui,arial,sans-serif;
  }
</style>

</head>
<body><p><a name="nav-menu" id="nav-menu"><strong>Contents</strong></a></p>

<ul>
    
    <li>
      <a href="/mt3501-lnotes/">
      
      Home
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/01-intro">
      
      Section 1 - Intro
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/02-vector-spaces">
      
      Section 2 - Vector spaces
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/03-algorithms-to-live-by">
      
      Section 3 - Algorithms to live by
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/04-linear-transf">
      
      Section 4 - Linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/05-l-v-w">
      
      Section 5 - The vector space of linear transformations
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/06-direct-sums">
      
      Section 6 - Direct sums
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/07-dual-space">
      
      Section 7 - The dual space
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/08-eigen-stuff">
      
      Section 8 - Eigenvectors, eigenvalues, and the characteristic polynomial
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/09-diagonal">
      
      Section 9 - Diagonalisation
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/10-jnf">
      
      Section 10 - Jordan normal form
      </a>
    </li>
    
    <li>
      <a href="/mt3501-lnotes/11-inner-products">
      
      Section 11 - Inner products
      </a>
    </li>
    
</ul>



    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    





  </p>






<h1 id="chapter-vector-space-linear-transf">The vector space of linear transformations</h1>
<style type="text/css" scoped>
  body {
    counter-reset: chapter 4;
  }
</style>

<h2 id="mathcallv-w"><span class="math inline">\(\mathcal{L}(V, W)\)</span></h2>
<p>The theme of this part of the course is how to construct new vector spaces from existing ones.</p>
<div class="thm">
<p><span id="thm-hom-v-w" label="thm-hom-v-w"></span> Let <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> be a vector spaces over a field <span class="math inline">\(F\)</span> and let <span class="math inline">\(\mathcal{L}(V,  W)\)</span> denote the set of all linear transformations from <span class="math inline">\(V\)</span> to <span class="math inline">\(W\)</span>. Then <span class="math inline">\(\mathcal{L}(V, W)\)</span> is a vector space with addition and scalar multiplication are defined by <span class="math display">\[(S + T)(v) = S(v) + T(v) \qquad\text{and}\qquad (\alpha T)(v) = \alpha
    T(v)\]</span> for all <span class="math inline">\(v\in V\)</span>, and where <span class="math inline">\(S, T\in \mathcal{L}(V, W)\)</span> and <span class="math inline">\(\alpha \in F\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> See Problem 4 on Sheet II. ◻</p>
</div>
<p>Given that <span class="math inline">\(\mathcal{L}(V, W)\)</span> is a vector space we can ask all of the usual questions about <span class="math inline">\(\mathcal{L}(V, W)\)</span> that we might about any vector space: what is <span class="math inline">\(\dim \mathcal{L}(V, W)\)</span>? What is a basis for <span class="math inline">\(\mathcal{L}(V, W)\)</span>?</p>
<div class="thm">
<p><span id="thm-basis-for-hom" label="thm-basis-for-hom"></span> Let <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> be finite-dimensional vector spaces over the field <span class="math inline">\(F\)</span> and let <span class="math inline">\(\mathscr{B} = \{ v_{1},v_{2},\dots,v_{n} \}\)</span> and <span class="math inline">\(\mathscr{C} = \{  w_{1},w_{2},\dots,w_{m} \}\)</span> be bases for <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, respectively. Define linear transformations <span class="math inline">\(T_{k \ell} : V \to W\)</span> by: <span class="math display">\[T_{k \ell}(v_{\ell}) = w_{k}
    \quad
    \text{and}
    \quad
    T_{k \ell}(v_j) = \vec{0}
    \quad
    \text{for all}
    \quad
    j\not=\ell.\]</span> Then <span class="math inline">\(\mathscr{E} = \{T_{k \ell} : 1 \leq \ell \leq n, \; 1 \leq k \leq m\}\)</span> is a basis for <span class="math inline">\(\mathcal{L}(V, W)\)</span>, and so <span class="math inline">\(\dim \mathcal{L}(V, W) = \dim V \dim W\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> In Problem 7(a) on Sheet II, we showed that every linear transformation <span class="math inline">\(T  : V \to W\)</span> can be expressed as <span class="math display">\[T = \sum_{\substack{1 \leq \ell \leq n,\\1 \leq k \leq
        m}} \alpha_{k\ell} T_{k\ell}\]</span> for some scalars <span class="math inline">\(\alpha_{k\ell} \in F\)</span>. It follows that <span class="math inline">\(\operatorname{Span}{\mathscr{E}}  = \mathcal{L}(V, W)\)</span>.</p>
<p>In Problem 7(b) on Sheet II, we showed that <span class="math inline">\(\mathscr{E}\)</span> is linearly independent, and hence <span class="math display">\[\dim \mathcal{L}(V,W) = |\mathscr{E}| = \dim V \cdot \dim W.\]</span> ◻</p>
</div>
<div class="examp">
<p><span id="ex-L-F-V" label="ex-L-F-V"></span> Show that <span class="math inline">\(\mathcal{L}(\mathbb{R}, \mathbb{R} ^ 3)\)</span> is isomorphic to <span class="math inline">\(\mathbb{R} ^ 3\)</span>.</p>
</div>
<div class="solution">
<p>It follows from <a href="https://jdbm.me/mt3501-lnotes/05-l-v-w/#thm-basis-for-hom">Theorem 5.1.2</a> that <span class="math inline">\(\dim  \mathcal{L}(\mathbb{R}, \mathbb{R} ^ 3) = \dim \mathbb{R}\ \dim \mathbb{R} ^ 3 = 1 \cdot 3 = 3 = \dim \mathbb{R} ^ 3\)</span>. Since both <span class="math inline">\(\mathcal{L}(\mathbb{R}, \mathbb{R} ^ 3)\)</span> and <span class="math inline">\(\mathbb{R} ^ 3\)</span> are vector spaces over <span class="math inline">\(\mathbb{R}\)</span>, it follows by <a href="https://jdbm.me/mt3501-lnotes/04-linear-transf/#thm-isomorphism">Corollary 4.4.3</a> that <span class="math inline">\(\mathcal{L}(\mathbb{R}, \mathbb{R} ^ 3)\)</span> is isomorphic to <span class="math inline">\(\mathbb{R} ^  3\)</span>.</p>
<p>Note that, since isomorphic vector spaces are the “same”, by <a href="https://jdbm.me/mt3501-lnotes/04-linear-transf/#thm-isomorphism">Corollary 4.4.3</a>, we could think of the elements of <span class="math inline">\(\mathcal{L}(\mathbb{R}, \mathbb{R} ^  3)\)</span> as being <span class="math inline">\(3 \times 1\)</span> matrices with entries in <span class="math inline">\(\mathbb{R}\)</span>, or in other words, column vectors with entries in <span class="math inline">\(\mathbb{R}\)</span>!</p>
</div>
<p>Let <span class="math inline">\(F\)</span> be a field and let <span class="math inline">\(M_{m, n}(F)\)</span> denote the set of all <span class="math inline">\(m \times n\)</span> matrices with entries in <span class="math inline">\(F\)</span>. Then <span class="math inline">\(M_{m, n}(F)\)</span> is a vector space with addition (the usual addition of matrices) defined by: <span class="math display">\[\begin{pmatrix}
      \alpha_{11} &amp; \alpha_{12} &amp; \cdots &amp; \alpha_{1n} \\
      \alpha_{21}  &amp; \alpha_{22}  &amp; \cdots &amp; \alpha_{2n} \\
      \vdots                   &amp; \vdots                   &amp; \ddots &amp; \vdots        \\
      \alpha_{m1}  &amp; \alpha_{m2}  &amp; \cdots &amp; \alpha_{mn}     
    \end{pmatrix}
    \begin{pmatrix}
      \beta_{11} &amp; \beta_{12} &amp; \cdots &amp; \beta_{1n} \\
      \beta_{21}  &amp; \beta_{22}  &amp; \cdots &amp; \beta_{2n} \\
      \vdots                   &amp; \vdots                   &amp; \ddots &amp; \vdots        \\
      \beta_{m1}  &amp; \beta_{m2}  &amp; \cdots &amp; \beta_{mn}     
    \end{pmatrix}
    =
    \begin{pmatrix}
      \alpha_{11} + \beta_{11} &amp; \alpha_{12} + \beta_{12} &amp; \cdots &amp; \alpha_{1n}
      + \beta_{1n}                                                                 \\
      \alpha_{21} + \beta_{21} &amp; \alpha_{22} + \beta_{22} &amp; \cdots &amp; \alpha_{2n}
      + \beta_{2n}                                                                 \\
      \vdots                   &amp; \vdots                   &amp; \ddots &amp; \vdots        \\
      \alpha_{m1} + \beta_{m1} &amp; \alpha_{m2} + \beta_{m2} &amp; \cdots &amp; \alpha_{mn} +
      \beta_{mn}
    \end{pmatrix}\]</span> and scalar multiplication <span class="math display">\[\gamma 
    \begin{pmatrix}
      \alpha_{11} &amp; \alpha_{12} &amp; \cdots &amp; \alpha_{1n} \\
      \alpha_{21}  &amp; \alpha_{22}  &amp; \cdots &amp; \alpha_{2n} \\
      \vdots                   &amp; \vdots                   &amp; \ddots &amp; \vdots        \\
      \alpha_{m1}  &amp; \alpha_{m2}  &amp; \cdots &amp; \alpha_{mn}     
    \end{pmatrix}
    = 
    \begin{pmatrix}
      \gamma\alpha_{11} &amp; \alpha_{12} &amp; \cdots &amp; \alpha_{1n} \\
      \gamma\alpha_{21}  &amp; \alpha_{22}  &amp; \cdots &amp; \alpha_{2n} \\
      \vdots                   &amp; \vdots                   &amp; \ddots &amp; \vdots        \\
      \gamma\alpha_{m1}  &amp; \alpha_{m2}  &amp; \cdots &amp; \alpha_{mn}     
    \end{pmatrix}.\]</span> for <span class="math inline">\(\gamma \in F\)</span> and <span class="math inline">\([\alpha_{ij}], [\beta_{ij}] \in M_{m, n}(F)\)</span>. This follows by a similar argument to that given in the solution of Problem 1 on Sheet I.</p>
<div class="examp">
<p><span id="example-matrix-basis" label="example-matrix-basis"></span> Show that <span class="math display">\[\mathscr{F} = \left\{
    \begin{array}{rrclrclrcl}
      B_{11} &amp; = &amp;
      \begin{pmatrix}
        1 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0
      \end{pmatrix},
      B_{12} &amp; = &amp;
      \begin{pmatrix}
        0 &amp; 1 &amp; 0 \\
        0 &amp; 0 &amp; 0
      \end{pmatrix},
      B_{13} &amp; = &amp;
      \begin{pmatrix}
        0 &amp; 0 &amp; 1 \\
        0 &amp; 0 &amp; 0
      \end{pmatrix}, \\
      \\
      B_{21} &amp; = &amp;
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        1 &amp; 0 &amp; 0
      \end{pmatrix},
      B_{22} &amp; = &amp;
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 \\
      \end{pmatrix},
      B_{23} &amp; = &amp;
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 1 \\
      \end{pmatrix}
    \end{array}
    \right\}\]</span> is a basis for <span class="math inline">\(M_{3, 2}(\mathbb{R})\)</span>.</p>
</div>
<div class="solution">
<p>It suffices to show that <span class="math inline">\(\mathscr{F}\)</span> is a spanning set for <span class="math inline">\(M_{3,  2}(\mathbb{R})\)</span> and that <span class="math inline">\(\mathscr{F}\)</span> is linearly independent.</p>
<p>If <span class="math inline">\(A = [\alpha_{ij}] \in M_{3, 2}(\mathbb{R})\)</span> is any matrix, then <span class="math display">\[\begin{aligned}
    A &amp; = &amp; \begin{pmatrix}
      \alpha_{11} &amp; \alpha_{12} &amp; \alpha_{13} \\
      \alpha_{21} &amp; \alpha_{22} &amp; \alpha_{23} 
    \end{pmatrix}\\
     &amp; = &amp; 
     \alpha_{11}
      \begin{pmatrix}
        1 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0
      \end{pmatrix}
      + 
     \alpha_{12}
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 \\
      \end{pmatrix}
      + 
     \alpha_{13}
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 1 \\
      \end{pmatrix}
      \\
    &amp;&amp; 
    + \alpha_{21}
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        1 &amp; 0 &amp; 0 \\
      \end{pmatrix}
      + 
     \alpha_{22}
      \begin{pmatrix}
        0 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 
      \end{pmatrix}
      + 
     \alpha_{23}
      \begin{pmatrix}
        0 &amp; 0 &amp; 1 \\
        0 &amp; 0 &amp; 0
      \end{pmatrix}\\
    &amp; = &amp; 
    \alpha_{11}B_{11}
      + 
      \alpha_{12}B_{12}
      + 
     \alpha_{13}
     B_{13}
     + \alpha_{21}B_{21}
      + 
      \alpha_{22}B_{22}
     +
     \alpha_{23}B_{23}\in \operatorname{Span}(\mathscr{F}).
    \end{aligned}\]</span></p>
<p>To show that <span class="math inline">\(\mathscr{F}\)</span> is linearly independent, suppose that <span class="math display">\[\beta_{11} B_{11} + \beta_{12} B_{12} + \beta_{13} B_{13}
    +
    \beta_{21} B_{21} + \beta_{22} B_{22} + \beta_{23} B_{23} =
    \begin{pmatrix}
      0 &amp; 0 &amp; 0 \\
      0 &amp; 0 &amp; 0
    \end{pmatrix}.\]</span> Then, evaluating the left-hand side, we obtain that <span class="math display">\[\begin{pmatrix}
      \beta_{11} &amp; \beta_{12} &amp; \beta_{13} \\
      \beta_{21} &amp; \beta_{22} &amp; \beta_{23}
    \end{pmatrix} =
    \begin{pmatrix}
      0 &amp; 0 &amp; 0 \\
      0 &amp; 0 &amp; 0
    \end{pmatrix}\]</span> and so <span class="math inline">\(\beta_{11} = \beta_{12} = \beta_{13} = \beta_{21} = \beta_{22} =  \beta_{23} = 0\)</span>. Therefore <span class="math inline">\(\mathscr{F}\)</span> is linear independent, and hence a basis for <span class="math inline">\(M_{3, 2}(\mathbb{R})\)</span>.</p>
</div>
<div class="thm">
<p><span id="thm-basis-for-matrix" label="thm-basis-for-matrix"></span> Let <span class="math inline">\(m, n\in \mathbb{N}\)</span> be arbitrary. For every <span class="math inline">\(k\in \{1, \ldots, m\}\)</span> and every <span class="math inline">\(\ell \in \{1, \ldots, n\}\)</span>, we define <span class="math inline">\(B_{k \ell} \in M_{m, n}(F)\)</span> so that the only non-zero entry in <span class="math inline">\(B_{k\ell}\)</span> is the value <span class="math inline">\(1\)</span> in the <span class="math inline">\(k\)</span>-th row and <span class="math inline">\(\ell\)</span>-th column. Then <span class="math inline">\(\mathscr{F} = \{B_{k \ell} : 1 \leq \ell \leq n, \; 1 \leq k \leq m\}\)</span> is a basis for <span class="math inline">\(M_{m, n}(F)\)</span>, and so <span class="math inline">\(\dim M_{m, n}(F) = m n\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> It is routine to show that <span class="math inline">\(\mathscr{F}\)</span> spans <span class="math inline">\(M_{m, n}(F)\)</span> and that it is linearly independent. Hence <span class="math inline">\(\mathscr{F}\)</span> is a basis for <span class="math inline">\(M_{m, n}(F)\)</span>, as required. ◻</p>
</div>
<div class="thm">
<p><span id="thm-linear-transf-equal-matrices" label="thm-linear-transf-equal-matrices"></span> Let <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span> be vector spaces of dimensions <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span> over a field <span class="math inline">\(F\)</span> and let <span class="math inline">\(\mathscr{B}\)</span> and <span class="math inline">\(\mathscr{C}\)</span> be bases for <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, respectively. Then <span class="math inline">\(\Psi: \mathcal{L}(V, W) \to M_{m, n}(F)\)</span> defined by <span class="math display">\[\Psi(T) = \operatorname{Mat}_{\mathscr{B}, \mathscr{C}}(T)\quad \text{for all}\quad T \in \mathcal{L}(V, W)\]</span> is an isomorphism of vector spaces.</p>
</div>
<div class="proof">
<p><em>Proof.</em> By <a href="https://jdbm.me/mt3501-lnotes/04-linear-transf/#thm-bijection-basis">Theorem 4.4.2</a>, it suffices to show that <span class="math inline">\(\Psi\)</span> maps a basis of <span class="math inline">\(\mathcal{L}(V, W)\)</span> bijectively to a basis of <span class="math inline">\(M_{m, n}(F)\)</span>. The set <span class="math inline">\(\mathscr{E}= \{T_{kl} : 1\leq l \leq n,\ 1\leq k \leq m\}\)</span> given in <a href="https://jdbm.me/mt3501-lnotes/05-l-v-w/#thm-basis-for-hom">Theorem 5.1.2</a> is a basis for <span class="math inline">\(\mathcal{L}(V, W)\)</span>. Similarly, the set <span class="math inline">\(\mathscr{F} = \{B_{k \ell} : 1 \leq \ell \leq n, \; 1  \leq k \leq m\}\)</span> is a basis for <span class="math inline">\(M_{m, n}(F)\)</span> by <a href="https://jdbm.me/mt3501-lnotes/05-l-v-w/#thm-basis-for-matrix">Theorem 5.1.5</a>. A routine computation shows that <span class="math display">\[\operatorname{Mat}_{\mathscr{B}, \mathscr{C}}(T_{kl}) 
    = B_{kl}\]</span> for all <span class="math inline">\(k\)</span> and <span class="math inline">\(l\)</span>. ◻</p>
</div>
<div class="examp">
<p>Suppose that <span class="math inline">\(T : \mathbb{R} ^ 3 \to \mathbb{R} ^ 2\)</span> is defined by <span class="math display">\[T \begin{pmatrix} x \\ y \\ z \\ \end{pmatrix} = \begin{pmatrix} 2x \\ x + y \end{pmatrix}.\]</span> Write <span class="math inline">\(T\)</span> as an explicit linear combination of the basis vectors <span class="math inline">\(T_{kl}\)</span> defined in <a href="https://jdbm.me/mt3501-lnotes/05-l-v-w/#thm-basis-for-hom">Theorem 5.1.2</a>.</p>
</div>
<div class="solution">
<p>Let <span class="math inline">\(\mathscr{B} = \{\vec{e}_1, \vec{e}_2, \vec{e}_3\}\)</span> be the standard basis for <span class="math inline">\(\mathbb{R} ^ 3\)</span>, and let <span class="math inline">\(\mathscr{C} = \{\vec{f}_1, \vec{f}_2\}\)</span> be the standard basis for <span class="math inline">\(\mathbb{R} ^ 2\)</span>. Then <span class="math display">\[\operatorname{Mat}_{\mathscr{B}, \mathscr{C}}(T) =
    \begin{pmatrix}
      2 &amp; 0 &amp; 0 \\
      1 &amp; 1 &amp; 0
    \end{pmatrix}.\]</span> Since <span class="math inline">\(\mathscr{F}\)</span> from <a href="https://jdbm.me/mt3501-lnotes/05-l-v-w/#example-matrix-basis">Example 5.1.4</a> is a basis for <span class="math inline">\(M_{3, 2}(F)\)</span>, it follows that we may write <span class="math inline">\(\operatorname{Mat}_{\mathscr{B}, \mathscr{C}}(T)\)</span> as a unique linear combination of the vectors in <span class="math inline">\(\mathscr{B}\)</span>: <span class="math display">\[\operatorname{Mat}_{\mathscr{B}, \mathscr{C}}(T) =
    \begin{pmatrix}
      2 &amp; 0 &amp; 0 \\
      1 &amp; 1 &amp; 0
    \end{pmatrix}
    = 2B_{11} + B_{21} + B_{22}.\]</span> By the proof of <a href="https://jdbm.me/mt3501-lnotes/05-l-v-w/#thm-linear-transf-equal-matrices">Theorem 5.1.6</a>, the linear transformation <span class="math inline">\(\operatorname{Mat}_{\mathscr{B}, \mathscr{C}}: \mathcal{L}(V,  W) \to M_{m, n}(F)\)</span> is an isomorphism and <span class="math inline">\(\operatorname{Mat}_{\mathscr{B},  \mathscr{C}}(T_{kl}) = B_{kl}\)</span>. Hence <span class="math inline">\(T = 2T_{11} + T_{21} + T_{22}\)</span>.</p>
</div>







<p><a href="#">Back to top</a></p>
</body>
</html>
